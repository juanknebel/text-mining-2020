{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "import spacy\n",
    "# you need to run python -m spacy download en\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer, word_tokenize, sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import warnings, sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "path = Path(os.getcwd())\n",
    "sys.path.append(str(path.parent))\n",
    "warnings.filterwarnings('ignore')  \n",
    "%matplotlib inline\n",
    "data_directory = '../data'\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to /home/zero/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(f'{data_directory}/dreamers_summary.csv', sep='|')\n",
    "dream = pd.read_csv('../data/dreams_clean.csv', sep=';')\n",
    "# Borro aquellos sue√±os que no tienen palabras y aquellos en aleman que son los del grupo con id 18, 26 y 27\n",
    "dream = dream.dropna(axis=0, subset=['words']).drop(dream.loc[dream['group_id'].isin([18, 26, 27, 79, 80])].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      code       note                                        description  \\\n0        1       1957  The one at the Meads's house, where it's bigge...   \n1        2    8/11/67  I'm at a family reunion in a large fine house ...   \n2        3     8/1/85  I watch a plane fly past and shortly realize i...   \n3        4      1985?  Me pulling the green leaves and berries off so...   \n4        5      1985?  I'm in a room that reminds me of (but definite...   \n...    ...        ...                                                ...   \n36197   85  F, age 18  The dream was about me and my boyfriend going ...   \n36198   86  F, age 18  Two weeks ago this guy asked me to Senior Ball...   \n36199   87  F, age 18  My boyfriend just broke up with me so he was o...   \n36200   88  F, age 18  I was in my backyard and I was flying. I would...   \n36201   89  F, age 18  I felt scared. I was pregnant in my dream. The...   \n\n       words  group_id                     group dreamer sex dreamer age  \\\n0      154.0         1  Alta: a detailed dreamer      female       adult   \n1      248.0         1  Alta: a detailed dreamer      female       adult   \n2      303.0         1  Alta: a detailed dreamer      female       adult   \n3      468.0         1  Alta: a detailed dreamer      female       adult   \n4      561.0         1  Alta: a detailed dreamer      female       adult   \n...      ...       ...                       ...         ...         ...   \n36197  138.0        89  West Coast teenage girls      female    11 to 18   \n36198   96.0        89  West Coast teenage girls      female    11 to 18   \n36199  139.0        89  West Coast teenage girls      female    11 to 18   \n36200  104.0        89  West Coast teenage girls      female    11 to 18   \n36201   92.0        89  West Coast teenage girls      female    11 to 18   \n\n      dream years  numbers of dreams  \\\n0       1985-1997                422   \n1       1985-1997                422   \n2       1985-1997                422   \n3       1985-1997                422   \n4       1985-1997                422   \n...           ...                ...   \n36197   mid-1990s                 89   \n36198   mid-1990s                 89   \n36199   mid-1990s                 89   \n36200   mid-1990s                 89   \n36201   mid-1990s                 89   \n\n                                                 summary  id  total_words  \n0      Alta is an adult woman who wrote down her drea...   1     166351.0  \n1      Alta is an adult woman who wrote down her drea...   1     166351.0  \n2      Alta is an adult woman who wrote down her drea...   1     166351.0  \n3      Alta is an adult woman who wrote down her drea...   1     166351.0  \n4      Alta is an adult woman who wrote down her drea...   1     166351.0  \n...                                                  ...  ..          ...  \n36197  These dreams, from teenage girls ages 11-18, w...  89       9820.0  \n36198  These dreams, from teenage girls ages 11-18, w...  89       9820.0  \n36199  These dreams, from teenage girls ages 11-18, w...  89       9820.0  \n36200  These dreams, from teenage girls ages 11-18, w...  89       9820.0  \n36201  These dreams, from teenage girls ages 11-18, w...  89       9820.0  \n\n[36202 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n      <th>note</th>\n      <th>description</th>\n      <th>words</th>\n      <th>group_id</th>\n      <th>group</th>\n      <th>dreamer sex</th>\n      <th>dreamer age</th>\n      <th>dream years</th>\n      <th>numbers of dreams</th>\n      <th>summary</th>\n      <th>id</th>\n      <th>total_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1957</td>\n      <td>The one at the Meads's house, where it's bigge...</td>\n      <td>154.0</td>\n      <td>1</td>\n      <td>Alta: a detailed dreamer</td>\n      <td>female</td>\n      <td>adult</td>\n      <td>1985-1997</td>\n      <td>422</td>\n      <td>Alta is an adult woman who wrote down her drea...</td>\n      <td>1</td>\n      <td>166351.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>8/11/67</td>\n      <td>I'm at a family reunion in a large fine house ...</td>\n      <td>248.0</td>\n      <td>1</td>\n      <td>Alta: a detailed dreamer</td>\n      <td>female</td>\n      <td>adult</td>\n      <td>1985-1997</td>\n      <td>422</td>\n      <td>Alta is an adult woman who wrote down her drea...</td>\n      <td>1</td>\n      <td>166351.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>8/1/85</td>\n      <td>I watch a plane fly past and shortly realize i...</td>\n      <td>303.0</td>\n      <td>1</td>\n      <td>Alta: a detailed dreamer</td>\n      <td>female</td>\n      <td>adult</td>\n      <td>1985-1997</td>\n      <td>422</td>\n      <td>Alta is an adult woman who wrote down her drea...</td>\n      <td>1</td>\n      <td>166351.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1985?</td>\n      <td>Me pulling the green leaves and berries off so...</td>\n      <td>468.0</td>\n      <td>1</td>\n      <td>Alta: a detailed dreamer</td>\n      <td>female</td>\n      <td>adult</td>\n      <td>1985-1997</td>\n      <td>422</td>\n      <td>Alta is an adult woman who wrote down her drea...</td>\n      <td>1</td>\n      <td>166351.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1985?</td>\n      <td>I'm in a room that reminds me of (but definite...</td>\n      <td>561.0</td>\n      <td>1</td>\n      <td>Alta: a detailed dreamer</td>\n      <td>female</td>\n      <td>adult</td>\n      <td>1985-1997</td>\n      <td>422</td>\n      <td>Alta is an adult woman who wrote down her drea...</td>\n      <td>1</td>\n      <td>166351.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36197</th>\n      <td>85</td>\n      <td>F, age 18</td>\n      <td>The dream was about me and my boyfriend going ...</td>\n      <td>138.0</td>\n      <td>89</td>\n      <td>West Coast teenage girls</td>\n      <td>female</td>\n      <td>11 to 18</td>\n      <td>mid-1990s</td>\n      <td>89</td>\n      <td>These dreams, from teenage girls ages 11-18, w...</td>\n      <td>89</td>\n      <td>9820.0</td>\n    </tr>\n    <tr>\n      <th>36198</th>\n      <td>86</td>\n      <td>F, age 18</td>\n      <td>Two weeks ago this guy asked me to Senior Ball...</td>\n      <td>96.0</td>\n      <td>89</td>\n      <td>West Coast teenage girls</td>\n      <td>female</td>\n      <td>11 to 18</td>\n      <td>mid-1990s</td>\n      <td>89</td>\n      <td>These dreams, from teenage girls ages 11-18, w...</td>\n      <td>89</td>\n      <td>9820.0</td>\n    </tr>\n    <tr>\n      <th>36199</th>\n      <td>87</td>\n      <td>F, age 18</td>\n      <td>My boyfriend just broke up with me so he was o...</td>\n      <td>139.0</td>\n      <td>89</td>\n      <td>West Coast teenage girls</td>\n      <td>female</td>\n      <td>11 to 18</td>\n      <td>mid-1990s</td>\n      <td>89</td>\n      <td>These dreams, from teenage girls ages 11-18, w...</td>\n      <td>89</td>\n      <td>9820.0</td>\n    </tr>\n    <tr>\n      <th>36200</th>\n      <td>88</td>\n      <td>F, age 18</td>\n      <td>I was in my backyard and I was flying. I would...</td>\n      <td>104.0</td>\n      <td>89</td>\n      <td>West Coast teenage girls</td>\n      <td>female</td>\n      <td>11 to 18</td>\n      <td>mid-1990s</td>\n      <td>89</td>\n      <td>These dreams, from teenage girls ages 11-18, w...</td>\n      <td>89</td>\n      <td>9820.0</td>\n    </tr>\n    <tr>\n      <th>36201</th>\n      <td>89</td>\n      <td>F, age 18</td>\n      <td>I felt scared. I was pregnant in my dream. The...</td>\n      <td>92.0</td>\n      <td>89</td>\n      <td>West Coast teenage girls</td>\n      <td>female</td>\n      <td>11 to 18</td>\n      <td>mid-1990s</td>\n      <td>89</td>\n      <td>These dreams, from teenage girls ages 11-18, w...</td>\n      <td>89</td>\n      <td>9820.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>36202 rows √ó 13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = pd.merge(dream, summary, left_on='group_id', right_on='id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20\n",
    "\n",
    "data_samples = df['description'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracting tf-idf features for NMF...\ndone in 2.910s.\n"
    }
   ],
   "source": [
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracting tf features for LDA...\ndone in 2.835s.\n\n"
    }
   ],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting the NMF model (Frobenius norm) with tf-idf features, n_features=1000...\ndone in 3.552s.\n\nTopics in NMF model (Frobenius norm):\nTopic #0: said asked didn talking told wanted did thought looked came saying gave like called lady later know liked wasn walked\nTopic #1: man say says woman room look feel walk want comes tell ask ll don try small talk men come right\nTopic #2: like kind going just really little think know thing things stuff didn don dreamt doing laugh woke somebody sound sort\nTopic #3: mom ezra dad went shop darren home nana stuff got called movie thing going computer playing weird game phone bed\nTopic #4: went got saw came people room started door ran looked told left water didn tried place couldn walked outside took\nTopic #5: school eugene calvin class evelyn teacher dmitri darius samantha elijah high ms mr sat year bus people thing photos got\nTopic #6: car driving road drive drove got seat cars street parked going stopped stop driver fast truck police hill home parking\nTopic #7: guy girl watching movie like called guys liked thing bad people got place killed sex game friend playing shop weird\nTopic #8: dream remember don know friend dreamed interpretation questions answers woke felt night participant4 friends time actual setting just recall dreamt\nTopic #9: house mother old room door friend home father sister living lived brother family kitchen outside bed party window rooms street\n\n"
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_features=%d...\"\n",
    "      % (n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5)\n",
    "\n",
    "nmf.fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--------------------------------------------\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1    9073\n4    5995\n2    4145\n8    2817\n0    2779\n3    2669\n5    2460\n7    2237\n9    2135\n6    1892\nName: topic_number, dtype: int64"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "list_of_topics = []\n",
    "\n",
    "for topic_distribution in nmf.transform(tfidf_vectorizer.transform(data_samples[:])):\n",
    "    most_representative_topic = np.argsort(topic_distribution)[-1]\n",
    "    list_of_topics.append(most_representative_topic)\n",
    "\n",
    "topics_df = pd.DataFrame(list_of_topics, columns=['topic_number'])\n",
    "#print(topics_df)\n",
    "print(\"--------------------------------------------\")\n",
    "topics_df['topic_number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2.36610092e-06, 4.45563647e-02, 5.27550149e-03, ...,\n        4.46264501e-03, 2.48929040e-09, 4.39284553e-02],\n       [3.12010509e-03, 3.49051451e-02, 1.24793038e-05, ...,\n        1.80433427e-02, 2.84126956e-03, 5.52729359e-03],\n       [1.18032780e-02, 3.56934915e-02, 2.81379710e-03, ...,\n        4.40052562e-03, 3.08644873e-02, 2.15654012e-02],\n       ...,\n       [5.74195291e-03, 3.02004034e-16, 3.65921032e-02, ...,\n        2.82812817e-04, 4.14360945e-02, 1.54172270e-16],\n       [3.35858508e-10, 2.33888078e-02, 2.02882996e-06, ...,\n        9.15451765e-03, 4.29955540e-22, 1.81316670e-07],\n       [1.55329426e-02, 3.46480778e-04, 3.83974386e-04, ...,\n        5.92851305e-03, 4.95420948e-02, 2.19683570e-06]])"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "nmf.transform(tfidf_vectorizer.transform(data_samples[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.         0.0148101  0.00983771 0.         0.00353218 0.\n  0.00136396 0.         0.         0.0282674 ]]\n[[0.         0.25617979 0.17016915 0.         0.06109834 0.\n  0.02359331 0.         0.         0.48895941]]\n0.02826739870685852\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "9"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "transformed = nmf.transform(tfidf_vectorizer.transform(data_samples[:1]))\n",
    "print(transformed)\n",
    "print(transformed/transformed.sum(axis=1, keepdims=True))\n",
    "# Get the top predicted topic\n",
    "#predicted_topics = [np.argsort(each)[::-1][0] for each in transformed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_features=1000...\ndone in 12.939s.\n\nTopics in NMF model (generalized Kullback-Leibler divergence):\nTopic #0: said went came didn asked got told left looked wanted room thought saw later like did going took started couldn\nTopic #1: man say woman says feel want look comes tell like don walk try come ask large ll small men make\nTopic #2: like kind remember dream going just don really know think little dreamt thing woke things didn doing reason wasn time\nTopic #3: mom ezra dad shop home stuff car nana got thing darren going lots phone place food playing game house weird\nTopic #4: saw dream came dreamed went felt started walking interpretation mother street boy answers looked ran questions away suddenly building running\nTopic #5: school eugene calvin class teacher people playing dmitri evelyn high samantha year ms mr game elijah darius classmate went toilet\nTopic #6: car driving bus road drive street going seat train walking stop truck ride hill riding cars driver drove plane home\nTopic #7: guy people water like place thing got girl big guys building ran boat bad trying lots pool killed gun kill\nTopic #8: girl friend watching movie father remember friends guy talking dream sex married love don years old died baby andrew brother\nTopic #9: house room bed door mother old sister like window living bedroom outside home kitchen floor brother party rooms family father\n\n"
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_features=%d...\"\n",
    "      % (n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5)\n",
    "\n",
    "nmf.fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[2.10115258e-05 3.95670536e-01 4.68476377e-02 2.48040615e-04\n  1.00993391e-05 6.42771144e-03 1.21051086e-01 3.96292977e-02\n  2.21054266e-08 3.90094558e-01]]\n1.0\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1]"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "transformed = nmf.transform(tfidf_vectorizer.transform(data_samples[:1]))\n",
    "print(transformed/transformed.sum(axis=1, keepdims=True))\n",
    "print(sum((transformed/transformed.sum(axis=1, keepdims=True))[0]))\n",
    "# Get the top predicted topic\n",
    "predicted_topics = [np.argsort(each)[::-1][0] for each in transformed]\n",
    "predicted_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting LDA models with tf features, n_features=1000...\ndone in 42.017s.\n\nTopics in LDA model:\nTopic #0: shop bus train wearing calvin clothes shirt pants shoes fat blue bag zombies black gay dress white dmitri lots pair\nTopic #1: dog plane samantha cat kids classmate flying fly school evelyn machine animals wally frank ship dogs island dawson cards bench\nTopic #2: house mother father friend brother sister old baby home room family truck boy girl uncle living bed wife parents dream\nTopic #3: man woman say room says like don want tell look walk people know feel think ask large comes talk men\nTopic #4: car street road driving going way building walking drive door hill people police seat got left cars right outside drove\nTopic #5: said went got came mom didn like guy saw looked people started told asked room going ezra dad couldn thought\nTopic #6: people guy game like gun playing man hit head away shot kill dead killed run black running trying ball ground\nTopic #7: dream class school dreamt book friend remember computer teacher paper dreams read girl tv questions movie like test time picture\nTopic #8: water eugene boat pool beach swimming dreamed fish doctor lake photo river kevin fishing rock sand swim jack big snow\nTopic #9: like going just kind know don remember really dream think little thing things didn sort time woke stuff people wasn\n\n"
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_features=%d...\"\n",
    "      % (n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.00200053 0.00200014 0.13155248 0.52419233 0.12359263 0.00200035\n  0.07003715 0.00200019 0.00200008 0.14062412]]\n1.0000000000000002\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[3]"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "transformed = lda.transform(tf_vectorizer.transform(data_samples[:1]))\n",
    "print(transformed)\n",
    "print(sum(transformed[0]))\n",
    "predicted_topics = [np.argsort(each)[::-1][0] for each in transformed]\n",
    "predicted_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}