{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Estefi\\Anaconda3\\lib\\site-packages\\past\\builtins\\misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from gensim import similarities\n",
    "from string import punctuation\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "import spacy\n",
    "# you need to run python -m spacy download en\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer, word_tokenize, sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.manifold import TSNE \n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "import warnings, sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "path = Path(os.getcwd())\n",
    "sys.path.append(str(path.parent))\n",
    "warnings.filterwarnings('ignore')  \n",
    "%matplotlib inline\n",
    "#data_directory = '.'\n",
    "data_directory = '../data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Estefi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(f'{data_directory}/dreamers_summary.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dream = pd.read_csv(f'{data_directory}/dreams_clean.csv', sep=';')\n",
    "# Borro aquellos sue√±os que no tienen palabras y aquellos en aleman que son los del grupo con id 18, 26 y 27\n",
    "dream = dream.dropna(axis=0, subset=['words']).drop(dream.loc[dream['group_id'].isin([18, 26, 27, 79, 80])].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>note</th>\n",
       "      <th>description</th>\n",
       "      <th>words</th>\n",
       "      <th>group_id</th>\n",
       "      <th>group</th>\n",
       "      <th>dreamer sex</th>\n",
       "      <th>dreamer age</th>\n",
       "      <th>dream years</th>\n",
       "      <th>numbers of dreams</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "      <th>total_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1957</td>\n",
       "      <td>The one at the Meads's house, where it's bigge...</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>female</td>\n",
       "      <td>adult</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>422</td>\n",
       "      <td>Alta is an adult woman who wrote down her drea...</td>\n",
       "      <td>1</td>\n",
       "      <td>166351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8/11/67</td>\n",
       "      <td>I'm at a family reunion in a large fine house ...</td>\n",
       "      <td>248.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>female</td>\n",
       "      <td>adult</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>422</td>\n",
       "      <td>Alta is an adult woman who wrote down her drea...</td>\n",
       "      <td>1</td>\n",
       "      <td>166351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8/1/85</td>\n",
       "      <td>I watch a plane fly past and shortly realize i...</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>female</td>\n",
       "      <td>adult</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>422</td>\n",
       "      <td>Alta is an adult woman who wrote down her drea...</td>\n",
       "      <td>1</td>\n",
       "      <td>166351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1985?</td>\n",
       "      <td>Me pulling the green leaves and berries off so...</td>\n",
       "      <td>468.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>female</td>\n",
       "      <td>adult</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>422</td>\n",
       "      <td>Alta is an adult woman who wrote down her drea...</td>\n",
       "      <td>1</td>\n",
       "      <td>166351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1985?</td>\n",
       "      <td>I'm in a room that reminds me of (but definite...</td>\n",
       "      <td>561.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>female</td>\n",
       "      <td>adult</td>\n",
       "      <td>1985-1997</td>\n",
       "      <td>422</td>\n",
       "      <td>Alta is an adult woman who wrote down her drea...</td>\n",
       "      <td>1</td>\n",
       "      <td>166351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36197</td>\n",
       "      <td>85</td>\n",
       "      <td>F, age 18</td>\n",
       "      <td>The dream was about me and my boyfriend going ...</td>\n",
       "      <td>138.0</td>\n",
       "      <td>89</td>\n",
       "      <td>West Coast teenage girls</td>\n",
       "      <td>female</td>\n",
       "      <td>11 to 18</td>\n",
       "      <td>mid-1990s</td>\n",
       "      <td>89</td>\n",
       "      <td>These dreams, from teenage girls ages 11-18, w...</td>\n",
       "      <td>89</td>\n",
       "      <td>9820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36198</td>\n",
       "      <td>86</td>\n",
       "      <td>F, age 18</td>\n",
       "      <td>Two weeks ago this guy asked me to Senior Ball...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>89</td>\n",
       "      <td>West Coast teenage girls</td>\n",
       "      <td>female</td>\n",
       "      <td>11 to 18</td>\n",
       "      <td>mid-1990s</td>\n",
       "      <td>89</td>\n",
       "      <td>These dreams, from teenage girls ages 11-18, w...</td>\n",
       "      <td>89</td>\n",
       "      <td>9820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36199</td>\n",
       "      <td>87</td>\n",
       "      <td>F, age 18</td>\n",
       "      <td>My boyfriend just broke up with me so he was o...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>89</td>\n",
       "      <td>West Coast teenage girls</td>\n",
       "      <td>female</td>\n",
       "      <td>11 to 18</td>\n",
       "      <td>mid-1990s</td>\n",
       "      <td>89</td>\n",
       "      <td>These dreams, from teenage girls ages 11-18, w...</td>\n",
       "      <td>89</td>\n",
       "      <td>9820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36200</td>\n",
       "      <td>88</td>\n",
       "      <td>F, age 18</td>\n",
       "      <td>I was in my backyard and I was flying. I would...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>89</td>\n",
       "      <td>West Coast teenage girls</td>\n",
       "      <td>female</td>\n",
       "      <td>11 to 18</td>\n",
       "      <td>mid-1990s</td>\n",
       "      <td>89</td>\n",
       "      <td>These dreams, from teenage girls ages 11-18, w...</td>\n",
       "      <td>89</td>\n",
       "      <td>9820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36201</td>\n",
       "      <td>89</td>\n",
       "      <td>F, age 18</td>\n",
       "      <td>I felt scared. I was pregnant in my dream. The...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>89</td>\n",
       "      <td>West Coast teenage girls</td>\n",
       "      <td>female</td>\n",
       "      <td>11 to 18</td>\n",
       "      <td>mid-1990s</td>\n",
       "      <td>89</td>\n",
       "      <td>These dreams, from teenage girls ages 11-18, w...</td>\n",
       "      <td>89</td>\n",
       "      <td>9820.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36202 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      code       note                                        description  \\\n",
       "0        1       1957  The one at the Meads's house, where it's bigge...   \n",
       "1        2    8/11/67  I'm at a family reunion in a large fine house ...   \n",
       "2        3     8/1/85  I watch a plane fly past and shortly realize i...   \n",
       "3        4      1985?  Me pulling the green leaves and berries off so...   \n",
       "4        5      1985?  I'm in a room that reminds me of (but definite...   \n",
       "...    ...        ...                                                ...   \n",
       "36197   85  F, age 18  The dream was about me and my boyfriend going ...   \n",
       "36198   86  F, age 18  Two weeks ago this guy asked me to Senior Ball...   \n",
       "36199   87  F, age 18  My boyfriend just broke up with me so he was o...   \n",
       "36200   88  F, age 18  I was in my backyard and I was flying. I would...   \n",
       "36201   89  F, age 18  I felt scared. I was pregnant in my dream. The...   \n",
       "\n",
       "       words  group_id                     group dreamer sex dreamer age  \\\n",
       "0      154.0         1  Alta: a detailed dreamer      female       adult   \n",
       "1      248.0         1  Alta: a detailed dreamer      female       adult   \n",
       "2      303.0         1  Alta: a detailed dreamer      female       adult   \n",
       "3      468.0         1  Alta: a detailed dreamer      female       adult   \n",
       "4      561.0         1  Alta: a detailed dreamer      female       adult   \n",
       "...      ...       ...                       ...         ...         ...   \n",
       "36197  138.0        89  West Coast teenage girls      female    11 to 18   \n",
       "36198   96.0        89  West Coast teenage girls      female    11 to 18   \n",
       "36199  139.0        89  West Coast teenage girls      female    11 to 18   \n",
       "36200  104.0        89  West Coast teenage girls      female    11 to 18   \n",
       "36201   92.0        89  West Coast teenage girls      female    11 to 18   \n",
       "\n",
       "      dream years  numbers of dreams  \\\n",
       "0       1985-1997                422   \n",
       "1       1985-1997                422   \n",
       "2       1985-1997                422   \n",
       "3       1985-1997                422   \n",
       "4       1985-1997                422   \n",
       "...           ...                ...   \n",
       "36197   mid-1990s                 89   \n",
       "36198   mid-1990s                 89   \n",
       "36199   mid-1990s                 89   \n",
       "36200   mid-1990s                 89   \n",
       "36201   mid-1990s                 89   \n",
       "\n",
       "                                                 summary  id  total_words  \n",
       "0      Alta is an adult woman who wrote down her drea...   1     166351.0  \n",
       "1      Alta is an adult woman who wrote down her drea...   1     166351.0  \n",
       "2      Alta is an adult woman who wrote down her drea...   1     166351.0  \n",
       "3      Alta is an adult woman who wrote down her drea...   1     166351.0  \n",
       "4      Alta is an adult woman who wrote down her drea...   1     166351.0  \n",
       "...                                                  ...  ..          ...  \n",
       "36197  These dreams, from teenage girls ages 11-18, w...  89       9820.0  \n",
       "36198  These dreams, from teenage girls ages 11-18, w...  89       9820.0  \n",
       "36199  These dreams, from teenage girls ages 11-18, w...  89       9820.0  \n",
       "36200  These dreams, from teenage girls ages 11-18, w...  89       9820.0  \n",
       "36201  These dreams, from teenage girls ages 11-18, w...  89       9820.0  \n",
       "\n",
       "[36202 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(dream, summary, left_on='group_id', right_on='id')\n",
    "df # Imprimo las primeras rows del df mergeado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cuenta con 593 sue√±os de Vietnam. El corpus tiene 80684 palabras.\n",
      "Se cuenta con 506 sue√±os de Phil, nuestro conjunto de control. El corpus tiene 85162 palabras.\n",
      "Se cuenta con 1093 sue√±os de Pegasus. El corpus tiene 135928 palabras.\n",
      "Se cuenta con 1235 sue√±os de Norman, nuestro conjunto de control. El corpus tiene 51340 palabras.\n"
     ]
    }
   ],
   "source": [
    "df_vietnam = df.loc[df['group'].isin(['Vietnam Vet: 1970-2008 war dreams', 'Vietnam Vet: 2015 dreams', 'Vietnam Vet: 2016-17 dreams'])]\n",
    "df_phil = df.loc[df['group'].isin(['Phil 1: teens', 'Phil 2: late 20s', 'Phil 3: retirement'])]\n",
    "df_pegasus = df.loc[df['group'].isin(['Pegasus: a factory worker'])]\n",
    "df_norman = df.loc[df['group'].isin(['Norman: a child molester'])]\n",
    "\n",
    "print(f\"Se cuenta con {len(df_vietnam)} sue√±os de Vietnam. El corpus tiene {int(df_vietnam['words'].sum())} palabras.\")\n",
    "print(f\"Se cuenta con {len(df_phil)} sue√±os de Phil, nuestro conjunto de control. El corpus tiene {int(df_phil['words'].sum())} palabras.\")\n",
    "print(f\"Se cuenta con {len(df_pegasus)} sue√±os de Pegasus. El corpus tiene {int(df_pegasus['words'].sum())} palabras.\")\n",
    "print(f\"Se cuenta con {len(df_norman)} sue√±os de Norman, nuestro conjunto de control. El corpus tiene {int(df_norman['words'].sum())} palabras.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['description'].values.tolist() # armamos la lista de sue√±os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El corpus tiene  36202  sue√±os y  2278397  tokens\n"
     ]
    }
   ],
   "source": [
    "#Solo palabras en minuscula sin signos de puntuaci√≥n. \n",
    "#Se eliminan stopwords y los tokens con menos de 4 caracteres.\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield([word for word in gensim.utils.simple_preprocess(str(sentence), deacc=True) if word not in stop_words and len(word) > 3])  # deacc=True removes punctuations\n",
    "data_words = list(sent_to_words(data))\n",
    "print(\"El corpus tiene \",len(data_words), \" sue√±os y \",sum([len(x) for x in data_words]),\" tokens\"   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>like</td>\n",
       "      <td>31946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>said</td>\n",
       "      <td>24258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>went</td>\n",
       "      <td>18802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>back</td>\n",
       "      <td>18726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>going</td>\n",
       "      <td>18163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>something</td>\n",
       "      <td>16874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>people</td>\n",
       "      <td>16021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>room</td>\n",
       "      <td>14034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>around</td>\n",
       "      <td>12161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>would</td>\n",
       "      <td>12138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>house</td>\n",
       "      <td>11532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>know</td>\n",
       "      <td>11143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>came</td>\n",
       "      <td>10460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>think</td>\n",
       "      <td>10263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>could</td>\n",
       "      <td>9298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>time</td>\n",
       "      <td>8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>really</td>\n",
       "      <td>8639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>thing</td>\n",
       "      <td>8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dream</td>\n",
       "      <td>8457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>someone</td>\n",
       "      <td>8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>little</td>\n",
       "      <td>8228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>remember</td>\n",
       "      <td>8115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>door</td>\n",
       "      <td>7658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>girl</td>\n",
       "      <td>7511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>place</td>\n",
       "      <td>7429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>school</td>\n",
       "      <td>7364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kind</td>\n",
       "      <td>7248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>left</td>\n",
       "      <td>7156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>started</td>\n",
       "      <td>6859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>trying</td>\n",
       "      <td>6847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>another</td>\n",
       "      <td>6797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>told</td>\n",
       "      <td>6783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>home</td>\n",
       "      <td>6587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>looked</td>\n",
       "      <td>6466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>asked</td>\n",
       "      <td>6432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>thought</td>\n",
       "      <td>6359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>woman</td>\n",
       "      <td>6306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>things</td>\n",
       "      <td>6277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>next</td>\n",
       "      <td>6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>looking</td>\n",
       "      <td>6239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count\n",
       "words           \n",
       "like       31946\n",
       "said       24258\n",
       "went       18802\n",
       "back       18726\n",
       "going      18163\n",
       "something  16874\n",
       "people     16021\n",
       "room       14034\n",
       "around     12161\n",
       "would      12138\n",
       "house      11532\n",
       "know       11143\n",
       "came       10460\n",
       "think      10263\n",
       "could       9298\n",
       "time        8655\n",
       "really      8639\n",
       "thing       8624\n",
       "dream       8457\n",
       "someone     8333\n",
       "little      8228\n",
       "remember    8115\n",
       "door        7658\n",
       "girl        7511\n",
       "place       7429\n",
       "school      7364\n",
       "kind        7248\n",
       "left        7156\n",
       "started     6859\n",
       "trying      6847\n",
       "another     6797\n",
       "told        6783\n",
       "home        6587\n",
       "looked      6466\n",
       "asked       6432\n",
       "thought     6359\n",
       "woman       6306\n",
       "things      6277\n",
       "next        6259\n",
       "looking     6239"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observo cuales son las palabras m√°s frecuentes del corpus.\n",
    "flat_list = [item for sublist in data_words for item in sublist]\n",
    "df = pd.DataFrame(flat_list, columns=['words'])\n",
    "df['count']=1\n",
    "df=df.groupby(['words']).count()\n",
    "df.sort_values(by=\"count\",ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi-gramas y Tri-gramas con el scoring default y se analiza el threshold si es correcto.\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de Bigramas con score_default  (40297, 2)\n",
      "Cantidad de Bigramas sin duplicados con score_default  (2094, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>31142</td>\n",
       "      <td>b'melvin rich'</td>\n",
       "      <td>100.281757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>b'stay overnight'</td>\n",
       "      <td>100.303272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30876</td>\n",
       "      <td>b'slope avenue'</td>\n",
       "      <td>100.475725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>b'bright sunny'</td>\n",
       "      <td>100.597337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24235</td>\n",
       "      <td>b'mixer board'</td>\n",
       "      <td>100.604456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2806</td>\n",
       "      <td>b'play clarinet'</td>\n",
       "      <td>100.905109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1059</td>\n",
       "      <td>b'furry animal'</td>\n",
       "      <td>101.013029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1428</td>\n",
       "      <td>b'sexual activity'</td>\n",
       "      <td>101.160565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24511</td>\n",
       "      <td>b'lights sirens'</td>\n",
       "      <td>101.357951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12202</td>\n",
       "      <td>b'killed giovanni'</td>\n",
       "      <td>101.437122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bigram       score\n",
       "31142      b'melvin rich'  100.281757\n",
       "130     b'stay overnight'  100.303272\n",
       "30876     b'slope avenue'  100.475725\n",
       "170       b'bright sunny'  100.597337\n",
       "24235      b'mixer board'  100.604456\n",
       "2806     b'play clarinet'  100.905109\n",
       "1059      b'furry animal'  101.013029\n",
       "1428   b'sexual activity'  101.160565\n",
       "24511    b'lights sirens'  101.357951\n",
       "12202  b'killed giovanni'  101.437122"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analizo los bigramas que armo el modelo de acuerdo a los parametros scoring default y threshold 100.\n",
    "df_bigramas =pd.DataFrame([x for x in bigram.export_phrases(data_words)],columns=[\"bigram\",\"score\"])\n",
    "print(\"Cantidad de Bigramas con score_default \",df_bigramas.shape)\n",
    "df_bigramas.drop_duplicates(inplace=True)\n",
    "print(\"Cantidad de Bigramas sin duplicados con score_default \",df_bigramas.shape)\n",
    "df_bigramas.sort_values(by=\"score\",ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2094.000000\n",
       "mean      2572.949817\n",
       "std       6111.878233\n",
       "min        100.281757\n",
       "25%        179.852715\n",
       "50%        421.704413\n",
       "75%       1597.172312\n",
       "max      51516.644628\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analizo los scores obtenidos y vemos que el maximos es 51mil y el minimo 100. Hay que ajustar este threshold.\n",
    "df_bigramas['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de Triigramas con score_default  (38595, 2)\n",
      "Cantidad de Triigramas sin duplicados con score_default  (1931, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7007</td>\n",
       "      <td>b'monty python'</td>\n",
       "      <td>9.695998e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11896</td>\n",
       "      <td>b'malcolm mcdowell'</td>\n",
       "      <td>2.751567e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10181</td>\n",
       "      <td>b'alma mater'</td>\n",
       "      <td>2.620540e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11031</td>\n",
       "      <td>b'colin farrell'</td>\n",
       "      <td>2.499592e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11338</td>\n",
       "      <td>b'angelina jolie'</td>\n",
       "      <td>2.096432e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29015</td>\n",
       "      <td>b'emerald reinhold'</td>\n",
       "      <td>1.191155e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14099</td>\n",
       "      <td>b'morena baccarin'</td>\n",
       "      <td>1.113730e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>b'visually impaired'</td>\n",
       "      <td>1.048216e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>b'cocker spaniel'</td>\n",
       "      <td>1.048216e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11913</td>\n",
       "      <td>b'quentin tarantino'</td>\n",
       "      <td>1.048216e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    trigram         score\n",
       "7007        b'monty python'  9.695998e+06\n",
       "11896   b'malcolm mcdowell'  2.751567e+06\n",
       "10181         b'alma mater'  2.620540e+06\n",
       "11031      b'colin farrell'  2.499592e+06\n",
       "11338     b'angelina jolie'  2.096432e+06\n",
       "29015   b'emerald reinhold'  1.191155e+06\n",
       "14099    b'morena baccarin'  1.113730e+06\n",
       "1360   b'visually impaired'  1.048216e+06\n",
       "315       b'cocker spaniel'  1.048216e+06\n",
       "11913  b'quentin tarantino'  1.048216e+06"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analizo los trigramas que armo el modelo de acuerdo a los parametros scoring default y threshold 100.\n",
    "#al pedir construir trigramas en base a los bigramas se ve que hay casos en donde hay cuatrogrmaas.Ej dawson_creek_dawson_joey\n",
    "df_trigramas =pd.DataFrame([x for x in trigram.export_phrases(data_words)],columns=[\"trigram\",\"score\"])\n",
    "print(\"Cantidad de Triigramas con score_default \",df_trigramas.shape)\n",
    "df_trigramas.drop_duplicates(inplace=True)\n",
    "print(\"Cantidad de Triigramas sin duplicados con score_default \",df_trigramas.shape)\n",
    "df_trigramas.sort_values(by=\"score\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.931000e+03\n",
       "mean     2.713222e+04\n",
       "std      2.636762e+05\n",
       "min      1.000559e+02\n",
       "25%      2.264458e+02\n",
       "50%      6.019132e+02\n",
       "75%      2.772273e+03\n",
       "max      9.695998e+06\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analizo los scores obtenidos y vemos que el maximos es 9millones y el minimo 100. Hay que ajustar este threshold.\n",
    "df_trigramas['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi-gramas y Tri-gramas con el scoring npmi y se analiza el threshold si es correcto.\n",
    "bigram = gensim.models.Phrases(data_words, min_count=10, threshold=0.5, scoring='npmi') # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], min_count=10, threshold=0.5, scoring='npmi')   \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de Bigramas con score npmi  (43182, 2)\n",
      "Cantidad de Bigramas sin duplicados con score npmi  (1126, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>b'freshman year'</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2884</td>\n",
       "      <td>b'telling truth'</td>\n",
       "      <td>0.500155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11153</td>\n",
       "      <td>b'snake bite'</td>\n",
       "      <td>0.500165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14154</td>\n",
       "      <td>b'ring tone'</td>\n",
       "      <td>0.500362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8524</td>\n",
       "      <td>b'kissed lips'</td>\n",
       "      <td>0.500423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8813</td>\n",
       "      <td>b'average size'</td>\n",
       "      <td>0.500550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>b'flesh blood'</td>\n",
       "      <td>0.500608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5896</td>\n",
       "      <td>b'perplexed participant'</td>\n",
       "      <td>0.500888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12239</td>\n",
       "      <td>b'police sirens'</td>\n",
       "      <td>0.500933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7873</td>\n",
       "      <td>b'banquet hall'</td>\n",
       "      <td>0.501371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         bigram     score\n",
       "5150           b'freshman year'  0.500001\n",
       "2884           b'telling truth'  0.500155\n",
       "11153             b'snake bite'  0.500165\n",
       "14154              b'ring tone'  0.500362\n",
       "8524             b'kissed lips'  0.500423\n",
       "8813            b'average size'  0.500550\n",
       "327              b'flesh blood'  0.500608\n",
       "5896   b'perplexed participant'  0.500888\n",
       "12239          b'police sirens'  0.500933\n",
       "7873            b'banquet hall'  0.501371"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analizo los bigramas que armo el modelo de acuerdo a los parametros scoring npmi y threshold 0.5.\n",
    "df_bigramas =pd.DataFrame([x for x in bigram.export_phrases(data_words)],columns=[\"bigram\",\"score\"])\n",
    "print(\"Cantidad de Bigramas con score npmi \", df_bigramas.shape)\n",
    "df_bigramas.drop_duplicates(inplace=True)\n",
    "print(\"Cantidad de Bigramas sin duplicados con score npmi \", df_bigramas.shape)\n",
    "df_bigramas.sort_values(by=\"score\",ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1126.000000\n",
       "mean        0.665482\n",
       "std         0.131949\n",
       "min         0.500001\n",
       "25%         0.554049\n",
       "50%         0.631904\n",
       "75%         0.751093\n",
       "max         1.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analizo los scores obtenidos para score npmi\n",
    "df_bigramas['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de Trigramas con score npmi  (42925, 2)\n",
      "Cantidad de Trigramas sin duplicados con score npmi  (1059, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8279</td>\n",
       "      <td>b'monty python'</td>\n",
       "      <td>1.649677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13287</td>\n",
       "      <td>b'queer folk'</td>\n",
       "      <td>1.409812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14688</td>\n",
       "      <td>b'jensen ackles'</td>\n",
       "      <td>1.403078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14187</td>\n",
       "      <td>b'malcolm mcdowell'</td>\n",
       "      <td>1.390499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14672</td>\n",
       "      <td>b'jared padalecki'</td>\n",
       "      <td>1.388598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12220</td>\n",
       "      <td>b'alma mater'</td>\n",
       "      <td>1.382275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915</td>\n",
       "      <td>b'roller coaster'</td>\n",
       "      <td>1.362195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13284</td>\n",
       "      <td>b'colin farrell'</td>\n",
       "      <td>1.341222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32029</td>\n",
       "      <td>b'emerald reinhold'</td>\n",
       "      <td>1.330820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>457</td>\n",
       "      <td>b'johnny depp'</td>\n",
       "      <td>1.329881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   trigram     score\n",
       "8279       b'monty python'  1.649677\n",
       "13287        b'queer folk'  1.409812\n",
       "14688     b'jensen ackles'  1.403078\n",
       "14187  b'malcolm mcdowell'  1.390499\n",
       "14672   b'jared padalecki'  1.388598\n",
       "12220        b'alma mater'  1.382275\n",
       "915      b'roller coaster'  1.362195\n",
       "13284     b'colin farrell'  1.341222\n",
       "32029  b'emerald reinhold'  1.330820\n",
       "457         b'johnny depp'  1.329881"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analizo los trigramas que armo el modelo de acuerdo a los parametros scoring npmi y threshold 0.5.\n",
    "#al pedir construir trigramas en base a los bigramas se ve que hay casos en donde hay cuatrogrmaas.Ej dawson_creek_dawson_joey\n",
    "df_trigramas =pd.DataFrame([x for x in trigram.export_phrases(data_words)],columns=[\"trigram\",\"score\"])\n",
    "print(\"Cantidad de Trigramas con score npmi \",df_trigramas.shape)\n",
    "df_trigramas.drop_duplicates(inplace=True)\n",
    "print(\"Cantidad de Trigramas sin duplicados con score npmi \",df_trigramas.shape)\n",
    "df_trigramas.sort_values(by=\"score\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1059.000000\n",
       "mean        0.717405\n",
       "std         0.187597\n",
       "min         0.500085\n",
       "25%         0.572983\n",
       "50%         0.666123\n",
       "75%         0.801927\n",
       "max         1.649677\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analizo los scores obtenidos para score npmi\n",
    "df_trigramas['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a___',\n",
       " 'a____',\n",
       " 'a_____',\n",
       " 'a______',\n",
       " 'able_bodied',\n",
       " 'aboard_ship',\n",
       " 'accounting_exam',\n",
       " 'accounting_test',\n",
       " 'across_street',\n",
       " 'acting_weird',\n",
       " 'actual_participant',\n",
       " 'adam_baldwin',\n",
       " 'adam_sandler',\n",
       " 'adrian_edmondson',\n",
       " 'advisor_mary',\n",
       " 'afraid_heights',\n",
       " 'african_american',\n",
       " 'aidan_gillen',\n",
       " 'alain_delon',\n",
       " 'alarm_clock',\n",
       " 'alarm_system',\n",
       " 'alexander_skarsgard',\n",
       " 'alice_wonderland',\n",
       " 'alma_mater',\n",
       " 'alphabetical_order',\n",
       " 'alternate_universe',\n",
       " 'alvin_broud',\n",
       " 'always_sunny',\n",
       " 'amb_______',\n",
       " 'american_flag',\n",
       " 'american_idol',\n",
       " 'amusement_park',\n",
       " 'and____came',\n",
       " 'andrea_bocelli',\n",
       " 'andrew_mccarthy',\n",
       " 'angelina_jolie',\n",
       " 'animal_crossing',\n",
       " 'annie_thomas',\n",
       " 'answering_machine',\n",
       " 'answers_questions',\n",
       " 'anxious_perplexed',\n",
       " 'apartment_complex',\n",
       " 'apollo____',\n",
       " 'archie_weber',\n",
       " 'armstrong_high',\n",
       " 'around____',\n",
       " 'arrested_development',\n",
       " 'artificial_respiration',\n",
       " 'asking_questions',\n",
       " 'attract_attention',\n",
       " 'aunt_bridget',\n",
       " 'aunt_charlotte',\n",
       " 'aunt_christine',\n",
       " 'aunt_elaine',\n",
       " 'aunt_janice',\n",
       " 'aunt_joyce',\n",
       " 'aunt_millie',\n",
       " 'aunt_naomi',\n",
       " 'aunt_polly',\n",
       " 'aunt_rosalie',\n",
       " 'aunt_sally',\n",
       " 'avenue_valley',\n",
       " 'average_size',\n",
       " 'awards_ceremony',\n",
       " 'away____',\n",
       " 'b___',\n",
       " 'b____',\n",
       " 'b_____',\n",
       " 'b______',\n",
       " 'b_______',\n",
       " 'b___________',\n",
       " 'ba____',\n",
       " 'baby_chicks',\n",
       " 'back_forth',\n",
       " 'bake_cookies',\n",
       " 'baked_beans',\n",
       " 'bancroft_middle',\n",
       " 'bang_bang',\n",
       " 'bang_theory',\n",
       " 'banquet_hall',\n",
       " 'barb_sanders',\n",
       " 'barbed_wire',\n",
       " 'barber_shop',\n",
       " 'barbie_doll',\n",
       " 'basketball_court',\n",
       " 'basketball_players',\n",
       " 'basketball_teammate',\n",
       " 'bathing_suit',\n",
       " 'bathing_suits',\n",
       " 'battle_royale',\n",
       " 'battlestar_galactica',\n",
       " 'bauer_avenue',\n",
       " 'beau____',\n",
       " 'becker_park',\n",
       " 'become_aware',\n",
       " 'bedside_table',\n",
       " 'bee_les',\n",
       " 'beep_beep',\n",
       " 'bell_rang',\n",
       " 'bellick_prison',\n",
       " 'belly_button',\n",
       " 'best_describe',\n",
       " 'beth_mock',\n",
       " 'bette_midler',\n",
       " 'bible_study',\n",
       " 'bill_clinton',\n",
       " 'bill_cosby',\n",
       " 'bill_f',\n",
       " 'bill_grove',\n",
       " 'bill_moseley',\n",
       " 'binky_ahmed',\n",
       " 'bird_seed',\n",
       " 'bits_pieces',\n",
       " 'bizarre_bizarre',\n",
       " 'bl___',\n",
       " 'blah_blah',\n",
       " 'blaze_orange',\n",
       " 'blond_hair',\n",
       " 'blonde_hair',\n",
       " 'blues_harp',\n",
       " 'bob______',\n",
       " 'body_snatchers',\n",
       " 'boom_boom',\n",
       " 'bottles_fridge',\n",
       " 'bowel_movement',\n",
       " 'bowling_alley',\n",
       " 'boxer_shorts',\n",
       " 'boxing_match',\n",
       " 'boyfriend_jeremy',\n",
       " 'boyhood_days',\n",
       " 'brad_pitt',\n",
       " 'bradley_cooper',\n",
       " 'breathing_heavily',\n",
       " 'brightly_colored',\n",
       " 'british_accent',\n",
       " 'britney_spears',\n",
       " 'brother_rodney',\n",
       " 'brother_stuart',\n",
       " 'brother_wally',\n",
       " 'brothers_sisters',\n",
       " 'bruce_springsteen',\n",
       " 'brush_teeth',\n",
       " 'brushing_teeth',\n",
       " 'bubba_hacker',\n",
       " 'buffy_buffy',\n",
       " 'buffy_vampire',\n",
       " 'bugging_bugging',\n",
       " 'bulletin_board',\n",
       " 'bunk_beds',\n",
       " 'bunny_cage',\n",
       " 'bunny_rabbit',\n",
       " 'burst_tears',\n",
       " 'burt_lancaster',\n",
       " 'buster_arrested',\n",
       " 'butcher_knife',\n",
       " 'c___',\n",
       " 'c____',\n",
       " 'c_____',\n",
       " 'c__________',\n",
       " 'c_______s',\n",
       " 'c_____s',\n",
       " 'ca__',\n",
       " 'called_______',\n",
       " 'calvin_silas',\n",
       " 'camping_trip',\n",
       " 'can___something',\n",
       " 'candy_bevner',\n",
       " 'candy_cane',\n",
       " 'cannot_identify',\n",
       " 'car_____',\n",
       " 'cardboard_boxes',\n",
       " 'carl_fisher',\n",
       " 'carter_church',\n",
       " 'carved_wood',\n",
       " 'cary_grant',\n",
       " 'cash_register',\n",
       " 'castle_beckett',\n",
       " 'catholic_church',\n",
       " 'cedar_park',\n",
       " 'celine_dion',\n",
       " 'cell_phone',\n",
       " 'cell_phones',\n",
       " 'center___',\n",
       " 'central_lutheran',\n",
       " 'certain_amount',\n",
       " 'ch____',\n",
       " 'ch_____',\n",
       " 'ch______',\n",
       " 'chain_link',\n",
       " 'charlton_heston',\n",
       " 'chemistry_exam',\n",
       " 'chest_drawers',\n",
       " 'chevy_chase',\n",
       " 'chicken_nuggets',\n",
       " 'chicken_treat',\n",
       " 'children_corn',\n",
       " 'chloe_smallville',\n",
       " 'chocolate_chip',\n",
       " 'choo_choo',\n",
       " 'chow_chow',\n",
       " 'chris_barrie',\n",
       " 'christian_bale',\n",
       " 'christian_james',\n",
       " 'christmas_decorations',\n",
       " 'christmas_presents',\n",
       " 'christopher_lloyd',\n",
       " 'christopher_ryan',\n",
       " 'christopher_walken',\n",
       " 'chuck_chuck',\n",
       " 'chucked_spaz',\n",
       " 'circuit_city',\n",
       " 'civil_rights',\n",
       " 'clark_kent',\n",
       " 'clark_marilou',\n",
       " 'classical_music',\n",
       " 'classmate_misty',\n",
       " 'cleaning_supplies',\n",
       " 'clementine_springs',\n",
       " 'client_company',\n",
       " 'climb_ladder',\n",
       " 'clint_eastwood',\n",
       " 'clockwork_orange',\n",
       " 'closed_blinds',\n",
       " 'closer_closer',\n",
       " 'co____',\n",
       " 'coconut_grove',\n",
       " 'colin_farrell',\n",
       " 'colin_mochrie',\n",
       " 'combing_hair',\n",
       " 'comic_strip',\n",
       " 'commit_suicide',\n",
       " 'committed_suicide',\n",
       " 'community_college',\n",
       " 'comp______',\n",
       " 'computer____',\n",
       " 'concession_stand',\n",
       " 'connected_amplifier',\n",
       " 'construction_site',\n",
       " 'construction_workers',\n",
       " 'continue_journey',\n",
       " 'convenience_store',\n",
       " 'conveyor_belt',\n",
       " 'cookie_dough',\n",
       " 'cory_monteith',\n",
       " 'counter_clockwise',\n",
       " 'cousin_abner',\n",
       " 'cousin_melvin',\n",
       " 'cousin_terence',\n",
       " 'craziest_part',\n",
       " 'cream_cone',\n",
       " 'credit_card',\n",
       " 'credit_cards',\n",
       " 'crew_member',\n",
       " 'crhp_sisters',\n",
       " 'cross_legged',\n",
       " 'crossword_puzzle',\n",
       " 'cruise_ship',\n",
       " 'cry_wolf',\n",
       " 'cubby_hole',\n",
       " 'cuckoo_nest',\n",
       " 'cuddles_gizmo',\n",
       " 'curly_hair',\n",
       " 'd___',\n",
       " 'd_____',\n",
       " 'd_cor',\n",
       " 'da_____',\n",
       " 'daily_double',\n",
       " 'dairy_queen',\n",
       " 'daniel_cerny',\n",
       " 'dannie_redding',\n",
       " 'darius_jeremiah',\n",
       " 'dark_complected',\n",
       " 'dark_haired',\n",
       " 'dark_skinned',\n",
       " 'darth_vader',\n",
       " 'daryl_yeller',\n",
       " 'daughter_christina',\n",
       " 'david_anders',\n",
       " 'david_bowie',\n",
       " 'david_cronenberg',\n",
       " 'david_lynch',\n",
       " 'david_mathew',\n",
       " 'david_tennant',\n",
       " 'david_walliams',\n",
       " 'dawn_dead',\n",
       " 'dawson_creek',\n",
       " 'dawson_joey',\n",
       " 'dead_bodies',\n",
       " 'dean_supernatural',\n",
       " 'debated_whether',\n",
       " 'debating_whether',\n",
       " 'decorated_christmas',\n",
       " 'deeper_deeper',\n",
       " 'deer_hunting',\n",
       " 'degree_angle',\n",
       " 'dennis_charlie',\n",
       " 'department_store',\n",
       " 'der___',\n",
       " 'dexter_dexter',\n",
       " 'dial_tone',\n",
       " 'diddled_diddled',\n",
       " 'diddling_dawdling',\n",
       " 'diddling_diddling',\n",
       " 'diesel_truck',\n",
       " 'digital_performer',\n",
       " 'dime_store',\n",
       " 'ding_ding',\n",
       " 'dining_room',\n",
       " 'directing_traffic',\n",
       " 'dirt_road',\n",
       " 'dirty_laundry',\n",
       " 'disc_jockey',\n",
       " 'diving_board',\n",
       " 'dmitri_seamus',\n",
       " 'dollar_bill',\n",
       " 'dollar_bills',\n",
       " 'donald_duck',\n",
       " 'doot_doot',\n",
       " 'downtown_wilmerton',\n",
       " 'draw_attention',\n",
       " 'drew_barrymore',\n",
       " 'drinking_beer',\n",
       " 'driver_license',\n",
       " 'driver_seat',\n",
       " 'drivers_seat',\n",
       " 'drug_addict',\n",
       " 'drug_deal',\n",
       " 'drug_dealer',\n",
       " 'drug_store',\n",
       " 'ducks_geese',\n",
       " 'dusk_till',\n",
       " 'dustin_hoffman',\n",
       " 'dylan_moran',\n",
       " 'e___',\n",
       " 'e____',\n",
       " 'e_____',\n",
       " 'eagle_lake',\n",
       " 'early_morning',\n",
       " 'easter_basket',\n",
       " 'easter_eggs',\n",
       " 'eastport_airport',\n",
       " 'edge_cliff',\n",
       " 'eldest_daughter',\n",
       " 'electric_shock',\n",
       " 'elementary_school',\n",
       " 'elevator_shaft',\n",
       " 'elijah_theodore',\n",
       " 'elise_rooks',\n",
       " 'elisha_cuthbert',\n",
       " 'else____',\n",
       " 'elvis_presley',\n",
       " 'emerald_reinhold',\n",
       " 'emergency_vehicles',\n",
       " 'emily_zates',\n",
       " 'enemy_soldiers',\n",
       " 'engaged_conversation',\n",
       " 'engagement_ring',\n",
       " 'english_accent',\n",
       " 'episode_outer',\n",
       " 'episode_supernatural',\n",
       " 'erect_penis',\n",
       " 'eric_bana',\n",
       " 'eric_christian',\n",
       " 'eric_idle',\n",
       " 'eric_stoner',\n",
       " 'eric_true',\n",
       " 'erik_stolhanske',\n",
       " 'ernie_ginny',\n",
       " 'esther_thurman',\n",
       " 'eugene_darius',\n",
       " 'eugene_pritchard',\n",
       " 'evelyn_darius',\n",
       " 'even_though',\n",
       " 'evening_gown',\n",
       " 'exactly_alike',\n",
       " 'excel_sheet',\n",
       " 'excel_spreadsheet',\n",
       " 'extension_cord',\n",
       " 'external_hard',\n",
       " 'f___',\n",
       " 'f____',\n",
       " 'f______',\n",
       " 'facial_hair',\n",
       " 'faded_consciousness',\n",
       " 'fading_consciousness',\n",
       " 'fallen_asleep',\n",
       " 'falling_apart',\n",
       " 'family_members',\n",
       " 'family_reunion',\n",
       " 'faster_faster',\n",
       " 'father_abraham',\n",
       " 'father_andrew',\n",
       " 'father_vance',\n",
       " 'favourite_character',\n",
       " 'feel_guilty',\n",
       " 'feel_queasy',\n",
       " 'feelings_thoughts',\n",
       " 'feet_diameter',\n",
       " 'fell_asleep',\n",
       " 'ferris_wheel',\n",
       " 'fianc_',\n",
       " 'fianc_e',\n",
       " 'fifteen_minutes',\n",
       " 'fill_form',\n",
       " 'fill_forms',\n",
       " 'final_destination',\n",
       " 'final_exam',\n",
       " 'fire_alarm',\n",
       " 'fire_drill',\n",
       " 'fish_pond',\n",
       " 'fish_tank',\n",
       " 'flashing_lights',\n",
       " 'flea_market',\n",
       " 'flesh_blood',\n",
       " 'flew_cuckoo',\n",
       " 'flight_stairs',\n",
       " 'flights_stairs',\n",
       " 'flower_petals',\n",
       " 'folding_chairs',\n",
       " 'football_players',\n",
       " 'football_stadium',\n",
       " 'foreign_country',\n",
       " 'foreign_language',\n",
       " 'former_girlfriend',\n",
       " 'fortune_teller',\n",
       " 'forward_backward',\n",
       " 'four_five',\n",
       " 'fran_susse',\n",
       " 'frank_whaley',\n",
       " 'fraternity_brothers',\n",
       " 'freaks_geeks',\n",
       " 'freddy_krueger',\n",
       " 'freezing_cold',\n",
       " 'french_accent',\n",
       " 'french_fries',\n",
       " 'french_toast',\n",
       " 'freshly_painted',\n",
       " 'freshman_year',\n",
       " 'fried_chicken',\n",
       " 'friend_mine',\n",
       " 'friendly_manner',\n",
       " 'fully_awake',\n",
       " 'fully_clothed',\n",
       " 'g___',\n",
       " 'g____',\n",
       " 'g_____',\n",
       " 'g______',\n",
       " 'gained_weight',\n",
       " 'gale_harold',\n",
       " 'game_thrones',\n",
       " 'garage_sale',\n",
       " 'garbage_cans',\n",
       " 'garbage_disposal',\n",
       " 'garden_hose',\n",
       " 'gavin_terrence',\n",
       " 'gentleman____',\n",
       " 'george_bluth',\n",
       " 'george_clooney',\n",
       " 'george_harrison',\n",
       " 'german_shepherd',\n",
       " 'getting_ready',\n",
       " 'giant_lizard',\n",
       " 'ginny_ernie',\n",
       " 'gino_teavor',\n",
       " 'girlfriend_annie',\n",
       " 'girlfriend_karen',\n",
       " 'girlfriend_natasha',\n",
       " 'give_cunnilingus',\n",
       " 'give_fellatio',\n",
       " 'gives_fellatio',\n",
       " 'giving_fellatio',\n",
       " 'glass_champagne',\n",
       " 'going______',\n",
       " 'gold_coast',\n",
       " 'golf_balls',\n",
       " 'golf_cart',\n",
       " 'golf_club',\n",
       " 'golf_clubs',\n",
       " 'golf_course',\n",
       " 'goosebumps_books',\n",
       " 'graduate_student',\n",
       " 'graham_chapman',\n",
       " 'grand_piano',\n",
       " 'grandma_agnes',\n",
       " 'grandma_grandpa',\n",
       " 'grandma_jane',\n",
       " 'grandma_maude',\n",
       " 'grandma_mildred',\n",
       " 'grandma_redding',\n",
       " 'grandpa_gerald',\n",
       " 'grandpa_grandma',\n",
       " 'grandpa_lloyd',\n",
       " 'grandpa_redding',\n",
       " 'grassed_area',\n",
       " 'great_deal',\n",
       " 'greeting_card',\n",
       " 'greg_david',\n",
       " 'greg_sestero',\n",
       " 'grey_anatomy',\n",
       " 'grocery_getto',\n",
       " 'grocery_shopping',\n",
       " 'grocery_store',\n",
       " 'guidance_office',\n",
       " 'guinea_pigs',\n",
       " 'guitar_hero',\n",
       " 'h___',\n",
       " 'h____',\n",
       " 'h_____',\n",
       " 'h______',\n",
       " 'had________',\n",
       " 'hair_straightener',\n",
       " 'haley_nathan',\n",
       " 'half_dozen',\n",
       " 'half_hour',\n",
       " 'halloween_costumes',\n",
       " 'hank_anderson',\n",
       " 'hardly_breathe',\n",
       " 'hardware_store',\n",
       " 'harmony_allure',\n",
       " 'harry_potter',\n",
       " 'heard_noise',\n",
       " 'heart_attack',\n",
       " 'heart_rate',\n",
       " 'heather_graham',\n",
       " 'heather_ramona',\n",
       " 'hermione_harry',\n",
       " 'hide_seek',\n",
       " 'high_heels',\n",
       " 'high_pitched',\n",
       " 'high_school',\n",
       " 'higher_higher',\n",
       " 'hiking_boots',\n",
       " 'hilarie_burton',\n",
       " 'hilary_nano',\n",
       " 'hind_legs',\n",
       " 'holly_lapson',\n",
       " 'holy_avenue',\n",
       " 'holy_grail',\n",
       " 'housemate_andre',\n",
       " 'housemate_stephen',\n",
       " 'hugged_kissed',\n",
       " 'hugging_kissing',\n",
       " 'hugh_laurie',\n",
       " 'human_biology',\n",
       " 'hundred_dollars',\n",
       " 'hundred_feet',\n",
       " 'i___he',\n",
       " 'inch_diameter',\n",
       " 'inch_thick',\n",
       " 'inches_diameter',\n",
       " 'inches_wide',\n",
       " 'index_finger',\n",
       " 'indiana_jones',\n",
       " 'inner_tube',\n",
       " 'insel____',\n",
       " 'inter_____',\n",
       " 'interpretation_none',\n",
       " 'intro_calc',\n",
       " 'invasion_body',\n",
       " 'iron_railing',\n",
       " 'ironing_board',\n",
       " 'ivory_alshire',\n",
       " 'izzy_conell',\n",
       " 'j_____',\n",
       " 'jack_nance',\n",
       " 'jack_nicholson',\n",
       " 'jack_thigpen',\n",
       " 'jackie_hunter',\n",
       " 'jake_gyllenhaal',\n",
       " 'james_beek',\n",
       " 'james_bond',\n",
       " 'james_lafferty',\n",
       " 'james_spader',\n",
       " 'jared_padalecki',\n",
       " 'jason_bateman',\n",
       " 'jason_segel',\n",
       " 'jayne_firefly',\n",
       " 'jeffrey_dean',\n",
       " 'jehovah_witness',\n",
       " 'jens_nils',\n",
       " 'jensen_ackles',\n",
       " 'jeremiah_alejandro',\n",
       " 'jeremiah_bradley',\n",
       " 'jeremiah_darius',\n",
       " 'jeremy_piven',\n",
       " 'jerry_kasper',\n",
       " 'jewel_staite',\n",
       " 'jigsaw_puzzle',\n",
       " 'jill_banks',\n",
       " 'jimmy_youngman',\n",
       " 'joey_dawson',\n",
       " 'john__________',\n",
       " 'john_cleese',\n",
       " 'john_kulik',\n",
       " 'john_lennon',\n",
       " 'john_travolta',\n",
       " 'johnny_depp',\n",
       " 'johnny_knoxville',\n",
       " 'jose_ramos',\n",
       " 'joshua_jackson',\n",
       " 'josie_bobby',\n",
       " 'joss_whedon',\n",
       " 'jumping_jacks',\n",
       " 'jungle_park',\n",
       " 'junior_high',\n",
       " 'justin_timberlake',\n",
       " 'k_____',\n",
       " 'k________',\n",
       " 'kari_otis',\n",
       " 'katherine_heigl',\n",
       " 'katie_holmes',\n",
       " 'kenny_hotz',\n",
       " 'kenny_spenny',\n",
       " 'kevin_simpson',\n",
       " 'kevin_spacey',\n",
       " 'kiefer_sutherland',\n",
       " 'killer_klowns',\n",
       " 'king_queen',\n",
       " 'king_sized',\n",
       " 'kiss_cheek',\n",
       " 'kiss_lips',\n",
       " 'kissed_cheek',\n",
       " 'kissed_lips',\n",
       " 'knees_____and',\n",
       " 'knick_knacks',\n",
       " 'kristen_stewart',\n",
       " 'kristy_puffy',\n",
       " 'l_____',\n",
       " 'lack_better',\n",
       " 'lana_lang',\n",
       " 'las____',\n",
       " 'laser_beam',\n",
       " 'last_night',\n",
       " 'laundry_basket',\n",
       " 'lawn_mower',\n",
       " 'lead_singer',\n",
       " 'leather_jacket',\n",
       " 'leaver_jacket',\n",
       " 'leighton_meester',\n",
       " 'licence_plate',\n",
       " 'license_plate',\n",
       " 'lifting_weights',\n",
       " 'light_bulb',\n",
       " 'light_bulbs',\n",
       " 'lighting_candles',\n",
       " 'linda_cardellini',\n",
       " 'liquor_store',\n",
       " 'listening_ipod',\n",
       " 'lite_mars',\n",
       " 'living_room',\n",
       " 'liza_minikel',\n",
       " 'loaf_bread',\n",
       " 'locke_lost',\n",
       " 'locked_doors',\n",
       " 'locking_doors',\n",
       " 'longtime_classmate',\n",
       " 'lord_rings',\n",
       " 'loren_dean',\n",
       " 'lose_weight',\n",
       " 'lost_lucidity',\n",
       " 'lost_weight',\n",
       " 'lower_level',\n",
       " 'lucid_dreaming',\n",
       " 'lucy_robert',\n",
       " 'lyle_zeffman',\n",
       " 'm___',\n",
       " 'm____',\n",
       " 'm_____',\n",
       " 'm______',\n",
       " 'magnifying_glass',\n",
       " 'main___',\n",
       " 'main_character',\n",
       " 'major_chord',\n",
       " 'making_jokes',\n",
       " 'malcolm_mcdowell',\n",
       " 'male_female',\n",
       " 'managed_escape',\n",
       " 'manual_wheelchair',\n",
       " 'marching_band',\n",
       " 'marge_drummond',\n",
       " 'mari_kate',\n",
       " 'marianne_stash',\n",
       " 'maribel__',\n",
       " 'marissa_camden',\n",
       " 'mark_wahlberg',\n",
       " 'marlon_brando',\n",
       " 'martial_arts',\n",
       " 'martin_sheen',\n",
       " 'mary_monroe',\n",
       " 'marybeth_neumann',\n",
       " 'mashed_potatoes',\n",
       " 'mason_cafeteria',\n",
       " 'maternal_grandma',\n",
       " 'maternal_grandpa',\n",
       " 'math_problems',\n",
       " 'matt_damon',\n",
       " 'matt_yams',\n",
       " 'matter_fact',\n",
       " 'matter_factly',\n",
       " 'mayall_adrian',\n",
       " 'mcdonald_breakfast',\n",
       " 'media_center',\n",
       " 'media_college',\n",
       " 'medium_build',\n",
       " 'melanie_mcdyss',\n",
       " 'melinda_chelsea',\n",
       " 'melvin_dahlheimer',\n",
       " 'melvin_redding',\n",
       " 'memorial_stadium',\n",
       " 'mental_hospital',\n",
       " 'mentally_retarded',\n",
       " 'merry_round',\n",
       " 'merton_circle',\n",
       " 'metal_pole',\n",
       " 'michael_cera',\n",
       " 'michael_emerson',\n",
       " 'michael_jordan',\n",
       " 'michael_palin',\n",
       " 'michael_rosenbaum',\n",
       " 'middle_aged',\n",
       " 'middle_nowhere',\n",
       " 'midvale_shops',\n",
       " 'mike_hollow',\n",
       " 'miles_hour',\n",
       " 'million_dollars',\n",
       " 'milo_ventimiglia',\n",
       " 'mini_disc',\n",
       " 'mint_cream',\n",
       " 'mirror_maze',\n",
       " 'mish_mash',\n",
       " 'misty_ryan',\n",
       " 'modern_media',\n",
       " 'montu_',\n",
       " 'monty_python',\n",
       " 'morena_baccarin',\n",
       " 'motor_scooter',\n",
       " 'mr_mcdowell',\n",
       " 'mryle_madden',\n",
       " 'multi_colored',\n",
       " 'multiple_choice',\n",
       " 'mushroom_cloud',\n",
       " 'musical_instruments',\n",
       " 'my_father',\n",
       " 'n____',\n",
       " 'n_____',\n",
       " 'n______',\n",
       " 'n_do_',\n",
       " 'nail_polish',\n",
       " 'nana_poppa',\n",
       " 'natasha_lens',\n",
       " 'nate_nelling',\n",
       " 'nathan_fillion',\n",
       " 'native_american',\n",
       " 'native_americans',\n",
       " 'neighbor_alvin',\n",
       " 'neil_flynn',\n",
       " 'neil_patrick',\n",
       " 'neither_pleasant',\n",
       " 'nelson_eastman',\n",
       " 'nervous_jerky',\n",
       " 'never_seen',\n",
       " 'newspaper_article',\n",
       " 'niagara_falls',\n",
       " 'nicole_peterson',\n",
       " 'nikki_',\n",
       " 'niles_zelling',\n",
       " 'nin_',\n",
       " 'no__',\n",
       " 'norman_noman',\n",
       " 'north_midvale',\n",
       " 'northeast_corner',\n",
       " 'northern_pike',\n",
       " 'northwest_corner',\n",
       " 'notre_dame',\n",
       " 'o___',\n",
       " 'o_____',\n",
       " 'obstacle_course',\n",
       " 'ocean_liner',\n",
       " 'oceanside_elementary',\n",
       " 'oddly_shaped',\n",
       " 'odds_ends',\n",
       " 'olden_days',\n",
       " 'olie_kecker',\n",
       " 'one_',\n",
       " 'onlooker_neither',\n",
       " 'opened_door',\n",
       " 'opposite_direction',\n",
       " 'oprah_winfrey',\n",
       " 'orange_juice',\n",
       " 'ordered_pizza',\n",
       " 'organ_loft',\n",
       " 'orlando_bloom',\n",
       " 'oscar_bluth',\n",
       " 'outer_limits',\n",
       " 'outer_space',\n",
       " 'p____',\n",
       " 'p_____',\n",
       " 'p______',\n",
       " 'p_________',\n",
       " 'p__peeing',\n",
       " 'pacey_dawson',\n",
       " 'paid_attention',\n",
       " 'pair_jeans',\n",
       " 'pair_scissors',\n",
       " 'parrot___',\n",
       " 'participant_neither',\n",
       " 'participant_pleasant',\n",
       " 'participant_unpleasant',\n",
       " 'particular_emotion',\n",
       " 'passenger_seat',\n",
       " 'passenger_side',\n",
       " 'pastor_gregg',\n",
       " 'patch_grass',\n",
       " 'patient_named',\n",
       " 'patient_ward',\n",
       " 'patrick_bergman',\n",
       " 'paul_jones',\n",
       " 'paul_mccartney',\n",
       " 'paul_newman',\n",
       " 'paul_whitehouse',\n",
       " 'paying_attention',\n",
       " 'peanut_butter',\n",
       " 'peavey_system',\n",
       " 'pen______',\n",
       " 'penn_teller',\n",
       " 'performing_arts',\n",
       " 'perplexed_actual',\n",
       " 'perplexed_participant',\n",
       " 'persia_miko',\n",
       " 'personal_player',\n",
       " 'petrol_station',\n",
       " 'phoebe_mills',\n",
       " 'phone_rang',\n",
       " 'photo_album',\n",
       " 'physical_contact',\n",
       " 'pickup_truck',\n",
       " 'picnic_table',\n",
       " 'piece_paper',\n",
       " 'pine_trees',\n",
       " 'ping_pong',\n",
       " 'pipe_organ',\n",
       " 'pitch_black',\n",
       " 'pitched_voice',\n",
       " 'plainview_high',\n",
       " 'playing_scrabble',\n",
       " 'pleasant_unpleasant',\n",
       " 'pleasantly_surprised',\n",
       " 'pokemon_diamond',\n",
       " 'polar_bear',\n",
       " 'police_officer',\n",
       " 'police_officers',\n",
       " 'police_sirens',\n",
       " 'portable_radio',\n",
       " 'post_apocalyptic',\n",
       " 'post_office',\n",
       " 'posted_facebook',\n",
       " 'potato_chips',\n",
       " 'pouring_rain',\n",
       " 'prep_academy',\n",
       " 'preparing_meal',\n",
       " 'press_button',\n",
       " 'pressed_button',\n",
       " 'pressing_button',\n",
       " 'prime_minister',\n",
       " 'printing_plant',\n",
       " 'printing_press',\n",
       " 'prison_break',\n",
       " 'proof_card',\n",
       " 'psychology_professor',\n",
       " 'pubic_hair',\n",
       " 'public_restroom',\n",
       " 'puerto_rican',\n",
       " 'pull_trigger',\n",
       " 'puppies_kittens',\n",
       " 'push_button',\n",
       " 'pushing_daisies',\n",
       " 'quantum_leap',\n",
       " 'quarter_inch',\n",
       " 'queen_billman',\n",
       " 'queer_folk',\n",
       " 'quentin_tarantino',\n",
       " 'quest_runescape',\n",
       " 'r_____',\n",
       " 'race_track',\n",
       " 'radio_station',\n",
       " 'railroad_track',\n",
       " 'railroad_tracks',\n",
       " 'rainn_wilson',\n",
       " 'ramona_tiana',\n",
       " 'random_guy',\n",
       " 'rang_bell',\n",
       " 'razor_blade',\n",
       " 're__',\n",
       " 'read_minds',\n",
       " 'real_life',\n",
       " 'reality_check',\n",
       " 'rear_view',\n",
       " 'received_letter',\n",
       " 'recollection_ends',\n",
       " 'recording_booth',\n",
       " 'redding_farm',\n",
       " 'reed_maxwell',\n",
       " 'remember_properly',\n",
       " 'remote_control',\n",
       " 'resort_area',\n",
       " 'retrace_steps',\n",
       " 'retreat_center',\n",
       " 'rhode_island',\n",
       " 'ride____',\n",
       " 'riding_bicycle',\n",
       " 'riding_bicycles',\n",
       " 'riding_bike',\n",
       " 'riding_bikes',\n",
       " 'riding_tandem',\n",
       " 'ring_finger',\n",
       " 'ring_tone',\n",
       " 'ripped_apart',\n",
       " 'roast_beef',\n",
       " 'robert_downey',\n",
       " 'robert_knepper',\n",
       " 'robert_niro',\n",
       " 'robert_pattinson',\n",
       " 'robin_williams',\n",
       " 'robyn_masters',\n",
       " 'rocking_chair',\n",
       " 'rode_bicycle',\n",
       " 'roller_blades',\n",
       " 'roller_blading',\n",
       " 'roller_coaster',\n",
       " 'roller_skate',\n",
       " 'roller_skates',\n",
       " 'roller_skating',\n",
       " 'romantic_interest',\n",
       " 'romantic_relationship',\n",
       " 'romantically_involved',\n",
       " 'roommate_chelsea',\n",
       " 'roommate_jens',\n",
       " 'roommate_sally',\n",
       " 'roommate_sean',\n",
       " 'roommate_stephen',\n",
       " 'root_beer',\n",
       " 'royal_show',\n",
       " 'rusty_redding',\n",
       " 'ryan_cartwright',\n",
       " 's____',\n",
       " 's_____',\n",
       " 's______',\n",
       " 's_______',\n",
       " 's________',\n",
       " 'samantha_sandra',\n",
       " 'sandra_derek',\n",
       " 'santa_claus',\n",
       " 'santa_cruz',\n",
       " 'sarah_chuck',\n",
       " 'sarah_reed',\n",
       " 'sarcastic_remark',\n",
       " 'saturday_market',\n",
       " 'saved_bell',\n",
       " 'sawyer_lost',\n",
       " 'scene_changes',\n",
       " 'scene_shifted',\n",
       " 'scene_shifts',\n",
       " 'scenic_point',\n",
       " 'science_fiction',\n",
       " 'science_museum',\n",
       " 'scotch_tape',\n",
       " 'scott_lowell',\n",
       " 'scrambled_eggs',\n",
       " 'screened_porch',\n",
       " 'scuba_diving',\n",
       " 'seamus_dmitri',\n",
       " 'sean_williams',\n",
       " 'searched_everywhere',\n",
       " 'seating_plan',\n",
       " 'security_guard',\n",
       " 'security_guards',\n",
       " 'self_centered',\n",
       " 'self_conscious',\n",
       " 'self_defense',\n",
       " 'sense_humor',\n",
       " 'sent_email',\n",
       " 'sent_message',\n",
       " 'serial_killer',\n",
       " 'service_merchandise',\n",
       " 'seth_rogen',\n",
       " 'seven_eight',\n",
       " 'several_times',\n",
       " 'sewing_machine',\n",
       " 'sexual_abuse',\n",
       " 'sexual_desire',\n",
       " 'sexual_encounter',\n",
       " 'sexual_excitement',\n",
       " 'sexual_intercourse',\n",
       " 'sexual_relations',\n",
       " 'sexually_aroused',\n",
       " 'sexually_excited',\n",
       " 'sha_____',\n",
       " 'shake_hands',\n",
       " 'shaun_micallef',\n",
       " 'shaving_cream',\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso los bigramas formados para el score npmi.\n",
    "data_grams=[bigram_mod[doc] for doc in data_words]\n",
    "result = []\n",
    "for dream_grams in data_grams:\n",
    "    for word in dream_grams:\n",
    "        if re.findall(r\".*_.*\", word):\n",
    "            result.append(word)\n",
    "result=list(set(result))\n",
    "result.sort()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a___',\n",
       " 'a____',\n",
       " 'a_____',\n",
       " 'a______',\n",
       " 'actual_participant_neither',\n",
       " 'actual_participant_neither_pleasant',\n",
       " 'actual_participant_pleasant',\n",
       " 'actual_participant_unpleasant',\n",
       " 'advisor_mary_monroe',\n",
       " 'always_sunny_philadelphia',\n",
       " 'amb_______',\n",
       " 'and____came',\n",
       " 'answers_questions_anxious',\n",
       " 'answers_questions_anxious_perplexed',\n",
       " 'answers_questions_perplexed',\n",
       " 'anxious_actual_participant',\n",
       " 'apollo____',\n",
       " 'armstrong_high_school',\n",
       " 'around____',\n",
       " 'aunt_christine_uncle_larry',\n",
       " 'aunt_janice_uncle_larry',\n",
       " 'away____',\n",
       " 'b___',\n",
       " 'b____',\n",
       " 'b_____',\n",
       " 'b______',\n",
       " 'b_______',\n",
       " 'b___________',\n",
       " 'ba____',\n",
       " 'bancroft_middle_school',\n",
       " 'beau____',\n",
       " 'bellick_prison_break',\n",
       " 'bl___',\n",
       " 'blah_blah_blah',\n",
       " 'blah_blah_blah_blah',\n",
       " 'bob______',\n",
       " 'boss_mike_hollow',\n",
       " 'brookland_high_school',\n",
       " 'buffy_vampire_slayer',\n",
       " 'buster_arrested_development',\n",
       " 'c___',\n",
       " 'c____',\n",
       " 'c_____',\n",
       " 'c__________',\n",
       " 'c_______s',\n",
       " 'c_____s',\n",
       " 'ca__',\n",
       " 'called_______',\n",
       " 'calvin_silas_samantha',\n",
       " 'can___something',\n",
       " 'car_____',\n",
       " 'center___',\n",
       " 'ch____',\n",
       " 'ch_____',\n",
       " 'ch______',\n",
       " 'chain_link_fence',\n",
       " 'charlie_always_sunny',\n",
       " 'chocolate_chip_cookies',\n",
       " 'clark_kent_smallville',\n",
       " 'classes_westport_college',\n",
       " 'classmate_gino_teavor',\n",
       " 'classmate_jerry_kasper',\n",
       " 'classmate_misty_ryan',\n",
       " 'co____',\n",
       " 'comp______',\n",
       " 'computer____',\n",
       " 'cousin_melvin_redding',\n",
       " 'd___',\n",
       " 'd_____',\n",
       " 'da_____',\n",
       " 'dawson_creek_dawson',\n",
       " 'dawson_creek_dawson_joey',\n",
       " 'dawson_dawson_creek',\n",
       " 'der___',\n",
       " 'doctor_david_tennant',\n",
       " 'dusk_till_dawn',\n",
       " 'e___',\n",
       " 'e____',\n",
       " 'e_____',\n",
       " 'else____',\n",
       " 'eric_christian_olsen',\n",
       " 'eric_true_blood',\n",
       " 'eugene_father_abraham',\n",
       " 'eugene_jeremiah_darius',\n",
       " 'f___',\n",
       " 'f____',\n",
       " 'f______',\n",
       " 'father_andrew_marissa',\n",
       " 'feelings_thoughts_happy',\n",
       " 'feelings_thoughts_scared',\n",
       " 'fire_alarm_system',\n",
       " 'flew_cuckoo_nest',\n",
       " 'former_girlfriend_karen',\n",
       " 'freddy_krueger_nightmare',\n",
       " 'friend_bubba_hacker',\n",
       " 'friend_kevin_simpson',\n",
       " 'friend_matt_yams',\n",
       " 'friend_melanie_mcdyss',\n",
       " 'friend_nate_nelling',\n",
       " 'friend_stephen_ramos',\n",
       " 'g___',\n",
       " 'g____',\n",
       " 'g_____',\n",
       " 'g______',\n",
       " 'gentleman____',\n",
       " 'george_grey_anatomy',\n",
       " 'girlfriend_annie_thomas',\n",
       " 'girlfriend_jackie_hunter',\n",
       " 'girlfriend_natasha_lens',\n",
       " 'going______',\n",
       " 'grade_teacher_liza',\n",
       " 'grandpa_grandma_redding',\n",
       " 'granma_uncle_gabriel',\n",
       " 'h___',\n",
       " 'h____',\n",
       " 'h_____',\n",
       " 'h______',\n",
       " 'had________',\n",
       " 'hank_anderson_norman_noman',\n",
       " 'happy_participant_pleasant',\n",
       " 'hermione_harry_potter',\n",
       " 'high_pitched_voice',\n",
       " 'high_school_classmate',\n",
       " 'high_school_classmates',\n",
       " 'high_school_teammate',\n",
       " 'housemate_stephen_ramos',\n",
       " 'i___he',\n",
       " 'insel____',\n",
       " 'inter_____',\n",
       " 'interpretation_none_answers_questions',\n",
       " 'invasion_body_snatchers',\n",
       " 'j_____',\n",
       " 'jared_padalecki_jensen_ackles',\n",
       " 'jeffrey_dean_morgan',\n",
       " 'jensen_ackles_jared_padalecki',\n",
       " 'joey_dawson_creek',\n",
       " 'john__________',\n",
       " 'k_____',\n",
       " 'k________',\n",
       " 'killer_klowns_outer_space',\n",
       " 'knees_____and',\n",
       " 'l_____',\n",
       " 'lana_lang_smallville',\n",
       " 'las____',\n",
       " 'long_sleeved_shirt',\n",
       " 'm___',\n",
       " 'm____',\n",
       " 'm_____',\n",
       " 'm______',\n",
       " 'main___',\n",
       " 'maribel__',\n",
       " 'maternal_grandma_jane',\n",
       " 'maternal_grandpa_gerald',\n",
       " 'mayall_adrian_edmondson',\n",
       " 'media_center_westport_high',\n",
       " 'midvale_high_school',\n",
       " 'mini_disc_recorder',\n",
       " 'modern_media_college',\n",
       " 'monty_python_holy_grail',\n",
       " 'n____',\n",
       " 'n_____',\n",
       " 'n______',\n",
       " 'n_do_',\n",
       " 'neighbor_alvin_broud',\n",
       " 'neil_patrick_harris',\n",
       " 'neither_pleasant_unpleasant',\n",
       " 'no__',\n",
       " 'o___',\n",
       " 'o_____',\n",
       " 'p____',\n",
       " 'p_____',\n",
       " 'p______',\n",
       " 'p_________',\n",
       " 'p__peeing',\n",
       " 'pacey_dawson_creek',\n",
       " 'parrot___',\n",
       " 'patient_ward_named',\n",
       " 'pen______',\n",
       " 'performing_arts_center',\n",
       " 'play_guitar_hero',\n",
       " 'playing_hide_seek',\n",
       " 'playing_world_warcraft',\n",
       " 'pokemon_diamond_pearl',\n",
       " 'poppa_uncle_wilbur',\n",
       " 'quest_world_warcraft',\n",
       " 'r_____',\n",
       " 're__',\n",
       " 'reality_check_worked',\n",
       " 'rear_view_mirror',\n",
       " 'ride____',\n",
       " 'rival_high_school',\n",
       " 'roommate_jens_nils',\n",
       " 'roommate_sean_williams',\n",
       " 'roommate_stephen_ramos',\n",
       " 's____',\n",
       " 's_____',\n",
       " 's______',\n",
       " 's_______',\n",
       " 's________',\n",
       " 'samantha_sandra_derek',\n",
       " 'sha_____',\n",
       " 'sisters_heather_ramona',\n",
       " 'slowly_faded_consciousness',\n",
       " 'social_arts_building',\n",
       " 'sookie_true_blood',\n",
       " 'spike_buffy_vampire_slayer',\n",
       " 'stained_glass_windows',\n",
       " 'star_spangled_banner',\n",
       " 'super_mario_galaxy',\n",
       " 't____',\n",
       " 't_____',\n",
       " 't______',\n",
       " 'teacher_liza_minikel',\n",
       " 'the____',\n",
       " 'they_____',\n",
       " 'those______',\n",
       " 'uncle_carl_aunt_joyce',\n",
       " 'uncle_charlie_aunt_polly',\n",
       " 'uncle_dannie_redding',\n",
       " 'uncle_rusty_redding',\n",
       " 'unknown_waking_life',\n",
       " 'w___',\n",
       " 'w____',\n",
       " 'w______',\n",
       " 'w________',\n",
       " 'wa______',\n",
       " 'walking____',\n",
       " 'was___',\n",
       " 'was____',\n",
       " 'watching_episode_outer',\n",
       " 'watching_kenny_spenny',\n",
       " 'watching_penn_teller',\n",
       " 'watching_supernatural_dean',\n",
       " 'water_bottles_fridge',\n",
       " 'wearing_spongebob_shirt',\n",
       " 'were___can',\n",
       " 'west_whitehall_primary',\n",
       " 'westport_high_school',\n",
       " 'working_printing_plant',\n",
       " 'xander_buffy_vampire_slayer',\n",
       " 'y_____',\n",
       " 'your____',\n",
       " 'zombies_dawn_dead']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso los trigramas formados para el score npmi.\n",
    "data_grams=[trigram_mod[bigram_mod[doc]] for doc in data_words]\n",
    "result = []\n",
    "for dream_grams in data_grams:\n",
    "    for word in dream_grams:\n",
    "        if re.findall(r\".*_.*_.*\", word):\n",
    "            result.append(word)\n",
    "result=list(set(result))\n",
    "result.sort()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids=['like','say','remember','dream','think','know','could','go','would','want','tell','thing','start','come','back','look','people','ask','seem','talk','make','take']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso  ['roller_skate'], ['roller_skates'],\n",
    "# Deberia hacerse lemantizacion sobre los tokens y luego hacer los bigramas. Habria que eliminar duplicados.\n",
    "def process_words(texts, stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "\n",
    "    \"\"\"Bigramas\"\"\"    \n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    \n",
    "    \"\"\"Trigramas\"\"\"   \n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    \n",
    "    \"\"\"Lemmatization\"\"\"\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "        \n",
    "    # remove stopwords once more after lemmatization y quito bad_ids\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words and word not in bad_ids and len(word) > 3] for doc in texts_out]    \n",
    "\n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words, stop_words)  # processed Text Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El corpus tiene  36202  sue√±os y  1432928  tokens,bigramas,lemas\n"
     ]
    }
   ],
   "source": [
    "print(\"El corpus tiene \",len(data_ready), \" sue√±os y \",sum([len(x) for x in data_ready]),\" tokens,bigramas,lemas\"   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant de Bigrmas sin dupliar  643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['three_four',\n",
       " 'body_snatcher',\n",
       " 'cruise_ship',\n",
       " 'kissed_lip',\n",
       " 'cary_grant',\n",
       " 'brother_stuart',\n",
       " 'gray_haire',\n",
       " 'midvale_shop',\n",
       " 'police_officer',\n",
       " 'chocolate_chip',\n",
       " 'flights_stairs',\n",
       " 'storm_brewe',\n",
       " 'outer_limit',\n",
       " 'remote_control',\n",
       " 'lord_ring',\n",
       " 'tigger_mitten',\n",
       " 'crhp_sister',\n",
       " 'chow_chow',\n",
       " 'british_accent',\n",
       " 'puppies_kitten',\n",
       " 'orange_juice',\n",
       " 'short_film',\n",
       " 'sexually_arouse',\n",
       " 'bowel_movement',\n",
       " 'golf_cart',\n",
       " 'facial_hair',\n",
       " 'feel_queasy',\n",
       " 'game_throne',\n",
       " 'peavey_system',\n",
       " 'shook_hand',\n",
       " 'climb_ladder',\n",
       " 'single_file',\n",
       " 'freshly_painted',\n",
       " 'light_skinned',\n",
       " 'chevy_chase',\n",
       " 'exactly_alike',\n",
       " 'bradley_cooper',\n",
       " 'felt_guilty',\n",
       " 'grand_piano',\n",
       " 'radio_station',\n",
       " 'summer_camp',\n",
       " 'dollar_bill',\n",
       " 'ping_pong',\n",
       " 'guinea_pigs',\n",
       " 'friend_mine',\n",
       " 'tall_slender',\n",
       " 'average_size',\n",
       " 'twin_bed',\n",
       " 'hundred_dollar',\n",
       " 'aunt_polly',\n",
       " 'locked_door',\n",
       " 'hardly_breathe',\n",
       " 'stuffed_animal',\n",
       " 'dark_haire',\n",
       " 'bunny_cage',\n",
       " 'lifting_weight',\n",
       " 'riding_tandem',\n",
       " 'kiss_cheek',\n",
       " 'thank_goodness',\n",
       " 'retrace_step',\n",
       " 'vivid_image',\n",
       " 'father_andrew',\n",
       " 'robert_downey',\n",
       " 'shopping_cart',\n",
       " 'tennis_court',\n",
       " 'drew_barrymore',\n",
       " 'lost_weight',\n",
       " 'niles_zelling',\n",
       " 'wicked_witch',\n",
       " 'sexual_relation',\n",
       " 'gino_teavor',\n",
       " 'c_______s',\n",
       " 'gold_coast',\n",
       " 'driver_seat',\n",
       " 'fully_clothed',\n",
       " 'pickup_truck',\n",
       " 'fine_art',\n",
       " 'whole_bunch',\n",
       " 'post_office',\n",
       " 'heard_noise',\n",
       " 'high_tech',\n",
       " 'enemy_soldier',\n",
       " 'four_five',\n",
       " 'screened_porch',\n",
       " 'french_frie',\n",
       " 'boom_boom',\n",
       " 'scene_changes',\n",
       " 'shopping_mall',\n",
       " 'santa_claus',\n",
       " 'banquet_hall',\n",
       " 'mint_cream',\n",
       " 'licence_plate',\n",
       " 'self_centere',\n",
       " 'fran_susse',\n",
       " 'hugging_kisse',\n",
       " 'darth_vader',\n",
       " 'shopping_center',\n",
       " 'passenger_seat',\n",
       " 'polar_bear',\n",
       " 'adam_baldwin',\n",
       " 'scene_shifts',\n",
       " 'belly_button',\n",
       " 'ironing_board',\n",
       " 'tree_branche',\n",
       " 'candy_bar',\n",
       " 'male_female',\n",
       " 'hugging_kissing',\n",
       " 'barb_sander',\n",
       " 'tony_kramer',\n",
       " 'seven_eight',\n",
       " 'total_darkness',\n",
       " 'christmas_tree',\n",
       " 'lower_level',\n",
       " 'elvis_presley',\n",
       " 'extension_cord',\n",
       " 'chemistry_exam',\n",
       " 'surround_sound',\n",
       " 'tree_hill',\n",
       " 'personal_player',\n",
       " 'freshman_year',\n",
       " 'wrapping_paper',\n",
       " 'railroad_tracks',\n",
       " 'train_track',\n",
       " 'united_state',\n",
       " 'vacuum_cleaner',\n",
       " 'recording_booth',\n",
       " 'aunt_esther',\n",
       " 'jack_nance',\n",
       " 'deer_hunte',\n",
       " 'grassed_area',\n",
       " 'sister_heather',\n",
       " 'beth_mock',\n",
       " 'skating_rink',\n",
       " 'redding_farm',\n",
       " 'edge_cliff',\n",
       " 'scotch_tape',\n",
       " 'self_defense',\n",
       " 'swinging_swe',\n",
       " 'degree_angle',\n",
       " 'heart_rate',\n",
       " 'coconut_grove',\n",
       " 'sheila_redding',\n",
       " 'celine_dion',\n",
       " 'carved_wood',\n",
       " 'managed_escape',\n",
       " 'bake_cookie',\n",
       " 'pouring_rain',\n",
       " 'slammed_brake',\n",
       " 'sarah_reed',\n",
       " 'knick_knack',\n",
       " 'inches_diamet',\n",
       " 'episode_season',\n",
       " 'elevator_shaft',\n",
       " 'circuit_city',\n",
       " 'junior_high',\n",
       " 'drivers_seat',\n",
       " 'bill_cosby',\n",
       " 'carter_school',\n",
       " 'shower_stall',\n",
       " 'riding_bike',\n",
       " 'vending_machine',\n",
       " 'quarter_inch',\n",
       " 'grocery_shoppe',\n",
       " 'faster_faster',\n",
       " 'fifteen_minute',\n",
       " 'john_lennon',\n",
       " 'bits_pieces',\n",
       " 'last_night',\n",
       " 'media_center',\n",
       " 'family_member',\n",
       " 'c_____s',\n",
       " 'nate_nelle',\n",
       " 'wilcox_center',\n",
       " 'cross_legge',\n",
       " 'loaf_bread',\n",
       " 'ward_name',\n",
       " 'roller_skating',\n",
       " 'sexually_excite',\n",
       " 'brightly_colore',\n",
       " 'able_bodied',\n",
       " 'portable_radio',\n",
       " 'south_wale',\n",
       " 'walked_past',\n",
       " 'bright_sunny',\n",
       " 'dawson_creek',\n",
       " 'phoebe_mill',\n",
       " 'become_aware',\n",
       " 'boyhood_day',\n",
       " 'shaun_micallef',\n",
       " 'eugene_darius',\n",
       " 'bang_theory',\n",
       " 'daniel_cerny',\n",
       " 'disc_jockey',\n",
       " 'liquor_store',\n",
       " 'half_hour',\n",
       " 'carl_fisher',\n",
       " 'slow_motion',\n",
       " 'battle_royale',\n",
       " 'baked_bean',\n",
       " 'lucid_dreaming',\n",
       " 'police_station',\n",
       " 'diving_board',\n",
       " 'tapped_shoulder',\n",
       " 'lost_lucidity',\n",
       " 'trick_treate',\n",
       " 'flower_petal',\n",
       " 'window_sill',\n",
       " 'dark_skinne',\n",
       " 'ryan_cartwright',\n",
       " 'monty_python',\n",
       " 'sawyer_lost',\n",
       " 'cross_legged',\n",
       " 'rode_bicycle',\n",
       " 'aunt_janice',\n",
       " 'closed_blind',\n",
       " 'native_american',\n",
       " 'roast_beef',\n",
       " 'leather_jacket',\n",
       " 'whitehall_high',\n",
       " 'great_deal',\n",
       " 'pushing_daisie',\n",
       " 'telephone_pole',\n",
       " 'catholic_church',\n",
       " 'higher_higher',\n",
       " 'rich_redde',\n",
       " 'ding_ding',\n",
       " 'david_tennant',\n",
       " 'leaver_jacket',\n",
       " 'sonya_nittle',\n",
       " 'taking_care',\n",
       " 'marissa_camden',\n",
       " 'puerto_rican',\n",
       " 'bird_seed',\n",
       " 'esther_thurman',\n",
       " 'fell_asleep',\n",
       " 'greeting_card',\n",
       " 'organ_loft',\n",
       " 'security_guard',\n",
       " 'emily_zate',\n",
       " 'pokemon_card',\n",
       " 'aunt_sally',\n",
       " 'prison_break',\n",
       " 'potato_chip',\n",
       " 'aboard_ship',\n",
       " 'adam_sandler',\n",
       " 'diddling_diddle',\n",
       " 'willow_redde',\n",
       " 'opposite_side',\n",
       " 'american_flag',\n",
       " 'aunt_elaine',\n",
       " 'getting_ready',\n",
       " 'riding_bikes',\n",
       " 'light_skinne',\n",
       " 'grandma_mildred',\n",
       " 'multi_colored',\n",
       " 'press_button',\n",
       " 'jensen_ackle',\n",
       " 'stanley_kubrick',\n",
       " 'shrug_shoulder',\n",
       " 'bette_midler',\n",
       " 'easter_basket',\n",
       " 'lack_bett',\n",
       " 'john_cleese',\n",
       " 'worker_tyler',\n",
       " 'french_accent',\n",
       " 'foreign_country',\n",
       " 'sound_system',\n",
       " 'teddy_bear',\n",
       " 'family_reunion',\n",
       " 'barbed_wire',\n",
       " 'hardware_store',\n",
       " 'gives_fellatio',\n",
       " 'telling_truth',\n",
       " 'terry_foss',\n",
       " 'shake_hand',\n",
       " 'shaving_cream',\n",
       " 'reed_maxwell',\n",
       " 'retreat_center',\n",
       " 'trick_treating',\n",
       " 'nathan_fillion',\n",
       " 'flights_step',\n",
       " 'scene_change',\n",
       " 'bible_study',\n",
       " 'willow_redding',\n",
       " 'closer_closer',\n",
       " 'matter_factly',\n",
       " 'tone_voice',\n",
       " 'dead_bodie',\n",
       " 'scrambled_egg',\n",
       " 'vague_ending',\n",
       " 'somewhere_else',\n",
       " 'dirt_road',\n",
       " 'trench_coat',\n",
       " 'record_player',\n",
       " 'afraid_heights',\n",
       " 'alma_mater',\n",
       " 'best_describe',\n",
       " 'dark_complected',\n",
       " 'alarm_system',\n",
       " 'license_plate',\n",
       " 'watching_slider',\n",
       " 'hugged_kisse',\n",
       " 'rich_redding',\n",
       " 'rocking_chair',\n",
       " 'freaks_geek',\n",
       " 'patch_grass',\n",
       " 'credit_card',\n",
       " 'laundry_basket',\n",
       " 'serial_kill',\n",
       " 'locke_lost',\n",
       " 'asking_question',\n",
       " 'obstacle_course',\n",
       " 'stick_shift',\n",
       " 'animal_crossing',\n",
       " 'joshua_jackson',\n",
       " 'eric_bana',\n",
       " 'spongebob_shirt',\n",
       " 'driver_license',\n",
       " 'beer_bottles',\n",
       " 'iron_railing',\n",
       " 'saturday_market',\n",
       " 'evening_gown',\n",
       " 'inner_tube',\n",
       " 'roller_skate',\n",
       " 'high_pitched',\n",
       " 'nail_polish',\n",
       " 'amusement_park',\n",
       " 'light_bulb',\n",
       " 'drinking_beer',\n",
       " 'hiking_boot',\n",
       " 'short_sleeve',\n",
       " 'teenage_boy',\n",
       " 'guitar_hero',\n",
       " 'christian_jame',\n",
       " 'client_company',\n",
       " 'pine_tree',\n",
       " 'steep_hill',\n",
       " 'chest_drawer',\n",
       " 'grocery_getto',\n",
       " 'railroad_track',\n",
       " 'tears_eye',\n",
       " 'roommate_sean',\n",
       " 'golf_clubs',\n",
       " 'study_abroad',\n",
       " 'train_station',\n",
       " 'picnic_table',\n",
       " 'mashed_potatoe',\n",
       " 'cardboard_boxe',\n",
       " 'clark_kent',\n",
       " 'slowly_fade',\n",
       " 'blaze_orange',\n",
       " 'passenger_side',\n",
       " 'hind_leg',\n",
       " 'father_vance',\n",
       " 'self_centered',\n",
       " 'bunny_rabbit',\n",
       " 'notre_dame',\n",
       " 'human_biology',\n",
       " 'brad_pitt',\n",
       " 'high_school',\n",
       " 'social_security',\n",
       " 'trading_space',\n",
       " 'matter_fact',\n",
       " 'friend_matt_yam',\n",
       " 'can___something',\n",
       " 'shrugs_shoulder',\n",
       " 'fish_pond',\n",
       " 'true_blood',\n",
       " 'conveyor_belt',\n",
       " 'daily_double',\n",
       " 'avenue_valley',\n",
       " 'reality_check',\n",
       " 'camping_trip',\n",
       " 'paul_whitehouse',\n",
       " 'ferris_wheel',\n",
       " 'early_morning',\n",
       " 'high_heels',\n",
       " 'early_morne',\n",
       " 'dark_complecte',\n",
       " 'jeremiah_darius',\n",
       " 'chain_link',\n",
       " 'commit_suicide',\n",
       " 'colin_farrell',\n",
       " 'fire_alarm',\n",
       " 'grandma_grandpa',\n",
       " 'grey_haire',\n",
       " 'roller_blade',\n",
       " 'erect_penis',\n",
       " 'burst_tear',\n",
       " 'pokemon_diamond',\n",
       " 'grocery_store',\n",
       " 'cookie_dough',\n",
       " 'trouble_finde',\n",
       " 'aunt_bridget',\n",
       " 'easter_eggs',\n",
       " 'high_heel',\n",
       " 'received_letter',\n",
       " 'barbie_doll',\n",
       " 'christian_bale',\n",
       " 'wishful_thinke',\n",
       " 'draw_attention',\n",
       " 'medium_build',\n",
       " 'printing_press',\n",
       " 'parking_space',\n",
       " 'stark_nake',\n",
       " 'waking_life',\n",
       " 'soul_mate',\n",
       " 'gale_harold',\n",
       " 'fire_drill',\n",
       " 'mental_hospital',\n",
       " 'science_fiction',\n",
       " 'flashing_light',\n",
       " 'matt_yam',\n",
       " 'race_track',\n",
       " 'outer_space',\n",
       " 'fully_clothe',\n",
       " 'tons_ton',\n",
       " 'bathing_suit',\n",
       " 'falling_apart',\n",
       " 'freezing_cold',\n",
       " 'cash_register',\n",
       " 'grandpa_redde',\n",
       " 'stainless_steel',\n",
       " 'comic_strip',\n",
       " 'grandma_jane',\n",
       " 'niles_zelle',\n",
       " 'self_conscious',\n",
       " 'tigger_mittens',\n",
       " 'wife_bonita',\n",
       " 'plainview_high',\n",
       " 'dial_tone',\n",
       " 'brothers_sister',\n",
       " 'cream_cone',\n",
       " 'pair_jean',\n",
       " 'archie_weber',\n",
       " 'robyn_master',\n",
       " 'making_jokes',\n",
       " 'fried_chicken',\n",
       " 'royal_show',\n",
       " 'parking_spaces',\n",
       " 'electric_shock',\n",
       " 'public_restroom',\n",
       " 'sound_booth',\n",
       " 'flesh_blood',\n",
       " 'english_accent',\n",
       " 'charlton_heston',\n",
       " 'making_joke',\n",
       " 'ernie_ginny',\n",
       " 'brother_wally',\n",
       " 'straw_barn',\n",
       " 'flea_market',\n",
       " 'swimming_pool',\n",
       " 'gained_weight',\n",
       " 'real_life',\n",
       " 'pair_shorts',\n",
       " 'mushroom_cloud',\n",
       " 'best_friend',\n",
       " 'dark_haired',\n",
       " 'merry_round',\n",
       " 'debated_whether',\n",
       " 'motor_scooter',\n",
       " 'vantage_point',\n",
       " 'photo_album',\n",
       " 'northern_pike',\n",
       " 'quest_runescape',\n",
       " 'mike_hollow',\n",
       " 'chicken_treat',\n",
       " 'sent_message',\n",
       " 'grandma_mildre',\n",
       " 'pair_short',\n",
       " 'vice_versa',\n",
       " 'wind_blowe',\n",
       " 'awards_ceremony',\n",
       " 'engagement_re',\n",
       " 'mirror_maze',\n",
       " 'speed_limit',\n",
       " 'credit_cards',\n",
       " 'ring_finger',\n",
       " 'eric_stoner',\n",
       " 'matt_damon',\n",
       " 'preparing_meal',\n",
       " 'martin_sheen',\n",
       " 'animal_crosse',\n",
       " 'petrol_station',\n",
       " 'spice_girl',\n",
       " 'lawn_mower',\n",
       " 'classical_music',\n",
       " 'real_estate',\n",
       " 'cousin_terence',\n",
       " 'riding_bicycle',\n",
       " 'friendly_manner',\n",
       " 'shoulder_strap',\n",
       " 'shoulder_length',\n",
       " 'tomato_sauce',\n",
       " 'sexual_activity',\n",
       " 'bunk_beds',\n",
       " 'harmony_allure',\n",
       " 'bake_cookies',\n",
       " 'lucid_dreame',\n",
       " 'french_toast',\n",
       " 'michael_cera',\n",
       " 'peanut_butter',\n",
       " 'roller_coaster',\n",
       " 'someone_else',\n",
       " 'fish_tank',\n",
       " 'locking_door',\n",
       " 'robin_william',\n",
       " 'patrick_bergman',\n",
       " 'mari_kate',\n",
       " 'tape_recorder',\n",
       " 'burt_lancaster',\n",
       " 'sweet_roll',\n",
       " 'spoke_english',\n",
       " 'inches_diameter',\n",
       " 'living_quarter',\n",
       " 'steep_incline',\n",
       " 'sewing_machine',\n",
       " 'heart_attack',\n",
       " 'deer_hunting',\n",
       " 'inches_wide',\n",
       " 'stark_naked',\n",
       " 'craziest_part',\n",
       " 'fully_awake',\n",
       " 'middle_nowhere',\n",
       " 'scuba_dive',\n",
       " 'lose_weight',\n",
       " 'golf_ball',\n",
       " 'eric_idle',\n",
       " 'twin_peak',\n",
       " 'washing_machine',\n",
       " 'flight_stairs',\n",
       " 'lack_better',\n",
       " 'last_year',\n",
       " 'gavin_terrence',\n",
       " 'vaguely_aware',\n",
       " 'paid_attention',\n",
       " 'david_ander',\n",
       " 'gray_haired',\n",
       " 'chris_barrie',\n",
       " 'high_ceiling',\n",
       " 'telephone_booth',\n",
       " 'bathing_suits',\n",
       " 'merton_circle',\n",
       " 'pair_scissor',\n",
       " 'bill_grove',\n",
       " 'scene_shifted',\n",
       " 'wind_blowing',\n",
       " 'wired_sound',\n",
       " 'blonde_hair',\n",
       " 'major_chord',\n",
       " 'printing_plant',\n",
       " 'scene_shift',\n",
       " 'take_care',\n",
       " 'feel_guilty',\n",
       " 'blond_hair',\n",
       " 'even_though',\n",
       " 'several_time',\n",
       " 'skirt_blouse',\n",
       " 'living_room',\n",
       " 'fallen_asleep',\n",
       " 'bunk_bed',\n",
       " 'odds_end',\n",
       " 'wrapped_towel',\n",
       " 'fianc_e',\n",
       " 'marlon_brando',\n",
       " 'dining_hall',\n",
       " 'chicken_nugget',\n",
       " 'ginny_ernie',\n",
       " 'somebody_else',\n",
       " 'trouble_finding',\n",
       " 'sarah_ree',\n",
       " 'roommate_sally',\n",
       " 'high_pitche',\n",
       " 'bulletin_board',\n",
       " 'theme_park',\n",
       " 'virtual_reality',\n",
       " 'ring_tone',\n",
       " 'engagement_ring',\n",
       " 'single_bed',\n",
       " 'whose_name',\n",
       " 'write_essay',\n",
       " 'goosebumps_book',\n",
       " 'steering_wheel',\n",
       " 'short_sleeved',\n",
       " 'roller_blades',\n",
       " 'bits_piece',\n",
       " 'and____came',\n",
       " 'taken_aback',\n",
       " 'queer_folk',\n",
       " 'pitch_black',\n",
       " 'toilet_flushe',\n",
       " 'deeper_deeper',\n",
       " 'tape_player',\n",
       " 'graham_chapman',\n",
       " 'clark_marilou',\n",
       " 'eldest_daughter',\n",
       " 'harry_potter',\n",
       " 'oddly_shaped',\n",
       " 'stephen_ramos',\n",
       " 'inch_diameter',\n",
       " 'opened_door',\n",
       " 'station_wagon',\n",
       " 'back_forth',\n",
       " 'dusk_till_dawn',\n",
       " 'middle_age',\n",
       " 'vague_ende',\n",
       " 'dining_room',\n",
       " 'aunt_millie',\n",
       " 'grey_haired',\n",
       " 'tidal_wave',\n",
       " 'family_members',\n",
       " 'scene_shifte',\n",
       " 'oscar_bluth',\n",
       " 'york_city',\n",
       " 'boxing_match',\n",
       " 'lighting_candle',\n",
       " 'rhode_island',\n",
       " 'i___he',\n",
       " 'olie_kecker',\n",
       " 'flew_cuckoo_n',\n",
       " 'acting_weird',\n",
       " 'read_minds',\n",
       " 'flights_stair',\n",
       " 'garage_sale',\n",
       " 'football_player',\n",
       " 'cell_phone',\n",
       " 'kiss_lip',\n",
       " 'clint_eastwood',\n",
       " 'united_states',\n",
       " 'emily_zates',\n",
       " 'garbage_can',\n",
       " 'bedside_table',\n",
       " 'middle_aged',\n",
       " 'washing_dishe',\n",
       " 'science_museum',\n",
       " 'fill_form',\n",
       " 'lawn_mow',\n",
       " 'beer_bottle',\n",
       " 'freshly_painte',\n",
       " 'several_times',\n",
       " 'blonde_haire',\n",
       " 'alarm_clock',\n",
       " 'student_union']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analizar los bigramas de mi corpus. Los que queda luego de aplicar el modelo.\n",
    "result = []\n",
    "for dream_grams in data_ready:\n",
    "    for word in dream_grams:\n",
    "        if re.findall(r\".*_.*\", word):\n",
    "            result.append(word)\n",
    "result.sort()\n",
    "result=list(set(result))\n",
    "print(\"Cant de Bigrmas sin dupliar \",len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant de Trigrmas sin dupliar  8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['friend_matt_yam',\n",
       " 'can___something',\n",
       " 'c_____s',\n",
       " 'dusk_till_dawn',\n",
       " 'and____came',\n",
       " 'c_______s',\n",
       " 'i___he',\n",
       " 'flew_cuckoo_n']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analizar los trigramas de mi corpus. Los que queda luego de aplicar el modelo.\n",
    "result = []\n",
    "for dream_grams in data_ready:\n",
    "    for word in dream_grams:\n",
    "        if re.findall(r\".*_.*_.*\", word):\n",
    "            result.append(word)\n",
    "result.sort()\n",
    "result=list(set(result))\n",
    "print(\"Cant de Trigrmas sin dupliar \",len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "#Nos quedamos con los tokens que aparecen en al menos 10 documentos y que no aparezcan en mas del 50% de mi corpus.\n",
    "id2word.filter_extremes(no_below=10, no_above=0.5)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#de palabras en el diccionario 7012\n",
      "[(0, 'almost'), (1, 'arrive'), (2, 'aunt'), (3, 'balloon'), (4, 'blue'), (5, 'bridge'), (6, 'convertible'), (7, 'cooking'), (8, 'corner'), (9, 'couple'), (10, 'creek'), (11, 'cross'), (12, 'double'), (13, 'drive'), (14, 'drop'), (15, 'empty'), (16, 'european'), (17, 'fill'), (18, 'find'), (19, 'hallway'), (20, 'house'), (21, 'immediately'), (22, 'little'), (23, 'nice'), (24, 'outside'), (25, 'pick'), (26, 'play'), (27, 'room'), (28, 'round'), (29, 'second'), (30, 'short'), (31, 'side'), (32, 'sort'), (33, 'stre'), (34, 'tiny')]\n",
      "#ids en el  diccionario en todos los sue√±os 1106393\n",
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1)]]\n",
      "[['european', 'piper', 'sort', 'house', 'side', 'second', 'immediately', 'short', 'empty', 'hallway', 'turn', 'corner', 'find', 'tiny', 'room', 'young', 'woman', 'cooking', 'almost', 'fill', 'room', 'nice', 'outside', 'wait', 'aunt', 'pick', 'arrive', 'little', 'round', 'convertible', 'drive', 'cross', 'little', 'bridge', 'creek', 'double', 'drop', 'house', 'couple', 'play', 'stre', 'blue', 'balloon']]\n"
     ]
    }
   ],
   "source": [
    "print(\"#de palabras en el diccionario\",len(id2word.values()))\n",
    "print([item for item in id2word.items()][:35])\n",
    "print(\"#ids en el  diccionario en todos los sue√±os\",sum([len(x) for x in corpus]))\n",
    "print([item for item in corpus][:1])\n",
    "print([item for item in data_ready][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamulticore.LdaMulticore(workers=2,\n",
    "                                                corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=100, \n",
    "                                                random_state=100,\n",
    "                                                #update_every=1, default 1\n",
    "                                                #chunksize=10, default 2000\n",
    "                                                passes=10,\n",
    "                                                iterations = 2000,\n",
    "                                                #alpha='auto',\n",
    "                                                per_word_topics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.156*\"store\" + 0.035*\"sell\" + 0.031*\"counter\" + 0.028*\"work\" + 0.020*\"owner\" + 0.018*\"manager\" + 0.017*\"mall\" + 0.016*\"sale\" + 0.015*\"walk\" + 0.015*\"rack\"')\n",
      "(1, '0.065*\"naked\" + 0.053*\"dorm\" + 0.035*\"roommate\" + 0.030*\"trip\" + 0.026*\"balloon\" + 0.021*\"public\" + 0.021*\"brush\" + 0.020*\"bleacher\" + 0.020*\"government\" + 0.017*\"holiday\"')\n",
      "(2, '0.316*\"school\" + 0.040*\"animal\" + 0.028*\"tooth\" + 0.027*\"place\" + 0.022*\"leave\" + 0.018*\"teacher\" + 0.018*\"year\" + 0.017*\"give\" + 0.017*\"chip\" + 0.017*\"stuff\"')\n",
      "(3, '0.123*\"plane\" + 0.056*\"land\" + 0.048*\"film\" + 0.044*\"crash\" + 0.039*\"airport\" + 0.030*\"guard\" + 0.025*\"flight\" + 0.025*\"photograph\" + 0.024*\"crush\" + 0.024*\"priest\"')\n",
      "(4, '0.045*\"heart\" + 0.034*\"today\" + 0.030*\"rate\" + 0.025*\"sunny\" + 0.024*\"tank\" + 0.022*\"pound\" + 0.020*\"sword\" + 0.017*\"respect\" + 0.016*\"weak\" + 0.015*\"second\"')\n",
      "(5, '0.142*\"doctor\" + 0.054*\"angry\" + 0.050*\"reply\" + 0.045*\"charge\" + 0.027*\"chain\" + 0.026*\"indian\" + 0.022*\"cafe\" + 0.021*\"roll\" + 0.020*\"shock\" + 0.019*\"signal\"')\n",
      "(6, '0.100*\"toilet\" + 0.093*\"race\" + 0.087*\"classmate\" + 0.083*\"fellow\" + 0.070*\"ship\" + 0.060*\"exam\" + 0.030*\"math\" + 0.027*\"stall\" + 0.025*\"urinate\" + 0.025*\"experiment\"')\n",
      "(7, '0.084*\"wave\" + 0.040*\"sand\" + 0.025*\"stone\" + 0.021*\"huge\" + 0.018*\"shed\" + 0.014*\"slope\" + 0.014*\"bull\" + 0.014*\"ground\" + 0.013*\"walk\" + 0.013*\"move\"')\n",
      "(8, '0.179*\"drive\" + 0.042*\"stop\" + 0.030*\"road\" + 0.028*\"leave\" + 0.026*\"turn\" + 0.022*\"driver\" + 0.021*\"park\" + 0.020*\"front\" + 0.019*\"pull\" + 0.016*\"parking\"')\n",
      "(9, '0.050*\"piece\" + 0.036*\"collect\" + 0.034*\"cost\" + 0.028*\"trunk\" + 0.025*\"puzzle\" + 0.025*\"item\" + 0.023*\"give\" + 0.023*\"rubber\" + 0.019*\"elephant\" + 0.017*\"contest\"')\n",
      "(10, '0.187*\"sleep\" + 0.098*\"fight\" + 0.048*\"pretend\" + 0.042*\"asleep\" + 0.028*\"mail\" + 0.027*\"wake\" + 0.024*\"picnic\" + 0.022*\"night\" + 0.021*\"later\" + 0.019*\"refuse\"')\n",
      "(11, '0.183*\"table\" + 0.087*\"food\" + 0.055*\"restaurant\" + 0.044*\"dinner\" + 0.041*\"order\" + 0.034*\"plate\" + 0.021*\"serve\" + 0.017*\"bread\" + 0.015*\"cook\" + 0.014*\"wait\"')\n",
      "(12, '0.041*\"camera\" + 0.038*\"high\" + 0.035*\"view\" + 0.030*\"ledge\" + 0.024*\"blanket\" + 0.023*\"case\" + 0.021*\"piano\" + 0.017*\"body\" + 0.015*\"faster\" + 0.014*\"object\"')\n",
      "(13, '0.162*\"train\" + 0.081*\"track\" + 0.032*\"stop\" + 0.026*\"switch\" + 0.023*\"travel\" + 0.023*\"sandwich\" + 0.021*\"move\" + 0.021*\"hunt\" + 0.018*\"wait\" + 0.018*\"station\"')\n",
      "(14, '0.072*\"send\" + 0.049*\"cloud\" + 0.045*\"storm\" + 0.044*\"blow\" + 0.038*\"alien\" + 0.035*\"earth\" + 0.034*\"flip\" + 0.027*\"news\" + 0.025*\"contact\" + 0.020*\"hundred\"')\n",
      "(15, '0.258*\"call\" + 0.101*\"name\" + 0.094*\"phone\" + 0.049*\"number\" + 0.028*\"find\" + 0.018*\"home\" + 0.017*\"hear\" + 0.016*\"answer\" + 0.015*\"keep\" + 0.015*\"give\"')\n",
      "(16, '0.207*\"light\" + 0.069*\"pool\" + 0.052*\"dark\" + 0.047*\"turn\" + 0.041*\"climb\" + 0.023*\"green\" + 0.021*\"scary\" + 0.020*\"night\" + 0.018*\"cave\" + 0.018*\"gate\"')\n",
      "(17, '0.028*\"metal\" + 0.024*\"work\" + 0.021*\"foot\" + 0.020*\"hole\" + 0.020*\"pull\" + 0.019*\"break\" + 0.019*\"lift\" + 0.018*\"pipe\" + 0.015*\"hand\" + 0.015*\"section\"')\n",
      "(18, '0.151*\"class\" + 0.100*\"shoe\" + 0.091*\"card\" + 0.043*\"pair\" + 0.028*\"find\" + 0.028*\"give\" + 0.015*\"change\" + 0.015*\"sock\" + 0.015*\"first\" + 0.015*\"time\"')\n",
      "(19, '0.124*\"money\" + 0.052*\"steal\" + 0.046*\"give\" + 0.033*\"find\" + 0.033*\"shot\" + 0.027*\"search\" + 0.025*\"awoke\" + 0.020*\"shoot\" + 0.019*\"dollar\" + 0.016*\"power\"')\n",
      "(20, '0.074*\"knife\" + 0.049*\"text\" + 0.046*\"stab\" + 0.037*\"asian\" + 0.030*\"blind\" + 0.027*\"count\" + 0.026*\"word\" + 0.026*\"backyard\" + 0.026*\"trap\" + 0.026*\"language\"')\n",
      "(21, '0.279*\"play\" + 0.073*\"photo\" + 0.068*\"game\" + 0.044*\"draw\" + 0.037*\"joke\" + 0.022*\"basketball\" + 0.022*\"finger\" + 0.015*\"show\" + 0.015*\"face\" + 0.013*\"also\"')\n",
      "(22, '0.090*\"marry\" + 0.083*\"wedding\" + 0.046*\"cake\" + 0.042*\"ring\" + 0.033*\"gift\" + 0.032*\"married\" + 0.025*\"dress\" + 0.019*\"ceremony\" + 0.018*\"gang\" + 0.017*\"string\"')\n",
      "(23, '0.138*\"question\" + 0.101*\"answer\" + 0.047*\"coffee\" + 0.043*\"band\" + 0.038*\"smell\" + 0.027*\"address\" + 0.027*\"interview\" + 0.016*\"competition\" + 0.013*\"person\" + 0.013*\"wing\"')\n",
      "(24, '0.265*\"water\" + 0.066*\"boat\" + 0.041*\"rock\" + 0.040*\"swim\" + 0.025*\"beach\" + 0.018*\"deep\" + 0.018*\"lake\" + 0.017*\"slide\" + 0.013*\"bottom\" + 0.013*\"shore\"')\n",
      "(25, '0.102*\"stuff\" + 0.062*\"really\" + 0.058*\"game\" + 0.053*\"reason\" + 0.047*\"wake\" + 0.025*\"weird\" + 0.022*\"sudden\" + 0.021*\"home\" + 0.020*\"play\" + 0.019*\"everywhere\"')\n",
      "(26, '0.109*\"church\" + 0.098*\"seat\" + 0.033*\"aisle\" + 0.032*\"coin\" + 0.025*\"service\" + 0.022*\"front\" + 0.019*\"auditorium\" + 0.019*\"find\" + 0.017*\"pocket\" + 0.017*\"funeral\"')\n",
      "(27, '0.041*\"wash\" + 0.039*\"dirty\" + 0.027*\"dish\" + 0.024*\"tiny\" + 0.024*\"walk\" + 0.017*\"poison\" + 0.016*\"clean\" + 0.016*\"crack\" + 0.014*\"wheelchair\" + 0.014*\"dust\"')\n",
      "(28, '0.058*\"bedroom\" + 0.040*\"couch\" + 0.035*\"clean\" + 0.033*\"room\" + 0.027*\"closet\" + 0.018*\"hear\" + 0.017*\"porch\" + 0.015*\"sleep\" + 0.015*\"chair\" + 0.015*\"house\"')\n",
      "(29, '0.149*\"music\" + 0.099*\"listen\" + 0.055*\"play\" + 0.035*\"organ\" + 0.030*\"hear\" + 0.027*\"loud\" + 0.023*\"concert\" + 0.014*\"sound\" + 0.012*\"feel\" + 0.010*\"gravel\"')\n",
      "(30, '0.105*\"note\" + 0.080*\"happy\" + 0.052*\"study\" + 0.041*\"certain\" + 0.032*\"project\" + 0.031*\"extremely\" + 0.026*\"give\" + 0.025*\"telephone\" + 0.020*\"season\" + 0.017*\"working\"')\n",
      "(31, '0.058*\"familiar\" + 0.055*\"awake\" + 0.050*\"radio\" + 0.036*\"aunt\" + 0.032*\"deck\" + 0.021*\"uncle\" + 0.020*\"color\" + 0.019*\"design\" + 0.016*\"japanese\" + 0.016*\"deliver\"')\n",
      "(32, '0.017*\"large\" + 0.011*\"several\" + 0.010*\"begin\" + 0.009*\"point\" + 0.008*\"small\" + 0.008*\"stand\" + 0.008*\"rather\" + 0.008*\"person\" + 0.008*\"time\" + 0.008*\"foot\"')\n",
      "(33, '0.060*\"meeting\" + 0.033*\"system\" + 0.025*\"report\" + 0.017*\"attend\" + 0.015*\"member\" + 0.013*\"work\" + 0.012*\"first\" + 0.011*\"discussion\" + 0.010*\"possible\" + 0.010*\"last\"')\n",
      "(34, '0.166*\"ride\" + 0.139*\"horse\" + 0.059*\"drop\" + 0.042*\"drug\" + 0.037*\"mirror\" + 0.032*\"spray\" + 0.024*\"coach\" + 0.018*\"shadow\" + 0.017*\"grab\" + 0.016*\"pill\"')\n",
      "(35, '0.096*\"kind\" + 0.059*\"really\" + 0.051*\"little\" + 0.022*\"stuff\" + 0.018*\"sound\" + 0.015*\"time\" + 0.015*\"wake\" + 0.015*\"guess\" + 0.015*\"real\" + 0.013*\"suppose\"')\n",
      "(36, '0.132*\"boyfriend\" + 0.041*\"surround\" + 0.038*\"allow\" + 0.033*\"crazy\" + 0.033*\"lawn\" + 0.031*\"quarter\" + 0.030*\"garden\" + 0.029*\"prisoner\" + 0.024*\"prison\" + 0.022*\"poster\"')\n",
      "(37, '0.111*\"drink\" + 0.097*\"fence\" + 0.032*\"drunk\" + 0.026*\"argument\" + 0.019*\"current\" + 0.018*\"state\" + 0.018*\"anger\" + 0.017*\"tonight\" + 0.015*\"stop\" + 0.014*\"lying\"')\n",
      "(38, '0.217*\"throw\" + 0.103*\"ball\" + 0.049*\"world\" + 0.041*\"recall\" + 0.037*\"rope\" + 0.034*\"week\" + 0.013*\"true\" + 0.013*\"extra\" + 0.012*\"last\" + 0.011*\"pick\"')\n",
      "(39, '0.171*\"house\" + 0.033*\"zombie\" + 0.029*\"attack\" + 0.024*\"leave\" + 0.018*\"eventually\" + 0.018*\"stay\" + 0.016*\"outside\" + 0.016*\"find\" + 0.014*\"window\" + 0.013*\"later\"')\n",
      "(40, '0.169*\"kill\" + 0.127*\"dead\" + 0.029*\"chase\" + 0.020*\"person\" + 0.019*\"killer\" + 0.017*\"kick\" + 0.016*\"death\" + 0.014*\"online\" + 0.013*\"shot\" + 0.013*\"save\"')\n",
      "(41, '0.128*\"wear\" + 0.073*\"clothe\" + 0.064*\"shirt\" + 0.060*\"black\" + 0.056*\"dress\" + 0.052*\"pant\" + 0.034*\"blue\" + 0.034*\"white\" + 0.026*\"short\" + 0.021*\"hair\"')\n",
      "(42, '0.117*\"birthday\" + 0.087*\"tunnel\" + 0.086*\"bridge\" + 0.061*\"swing\" + 0.055*\"river\" + 0.050*\"period\" + 0.034*\"basket\" + 0.030*\"transfer\" + 0.026*\"raft\" + 0.023*\"mini\"')\n",
      "(43, '0.070*\"touch\" + 0.054*\"scream\" + 0.053*\"face\" + 0.032*\"head\" + 0.030*\"body\" + 0.027*\"skin\" + 0.019*\"scare\" + 0.016*\"hand\" + 0.015*\"wake\" + 0.015*\"best_friend\"')\n",
      "(44, '0.045*\"room\" + 0.027*\"become\" + 0.023*\"force\" + 0.022*\"chinese\" + 0.019*\"struggle\" + 0.015*\"feel\" + 0.014*\"bath\" + 0.012*\"fear\" + 0.012*\"presence\" + 0.012*\"breath\"')\n",
      "(45, '0.024*\"time\" + 0.021*\"leave\" + 0.021*\"realize\" + 0.020*\"decide\" + 0.017*\"maybe\" + 0.017*\"bill\" + 0.016*\"also\" + 0.013*\"need\" + 0.013*\"sure\" + 0.012*\"still\"')\n",
      "(46, '0.101*\"walk\" + 0.075*\"street\" + 0.072*\"tree\" + 0.052*\"road\" + 0.020*\"side\" + 0.018*\"turn\" + 0.018*\"stop\" + 0.013*\"city\" + 0.012*\"home\" + 0.012*\"right\"')\n",
      "(47, '0.074*\"word\" + 0.065*\"lunch\" + 0.038*\"busy\" + 0.031*\"locker\" + 0.026*\"cafeteria\" + 0.023*\"time\" + 0.019*\"forget\" + 0.018*\"silver\" + 0.018*\"place\" + 0.017*\"monitor\"')\n",
      "(48, '0.090*\"machine\" + 0.040*\"walk\" + 0.036*\"partner\" + 0.022*\"singer\" + 0.018*\"jacket\" + 0.018*\"hose\" + 0.014*\"laugh\" + 0.014*\"invisible\" + 0.014*\"show\" + 0.013*\"costume\"')\n",
      "(49, '0.062*\"circle\" + 0.024*\"performance\" + 0.020*\"feel\" + 0.019*\"blonde\" + 0.013*\"room\" + 0.013*\"movement\" + 0.012*\"much\" + 0.011*\"suppose\" + 0.011*\"piss\" + 0.011*\"surrounding\"')\n",
      "(50, '0.100*\"sort\" + 0.027*\"little\" + 0.023*\"rather\" + 0.021*\"place\" + 0.020*\"quite\" + 0.014*\"right\" + 0.013*\"much\" + 0.013*\"couple\" + 0.012*\"exactly\" + 0.011*\"apparently\"')\n",
      "(51, '0.165*\"shop\" + 0.151*\"lady\" + 0.083*\"fire\" + 0.030*\"place\" + 0.022*\"smoke\" + 0.018*\"stuff\" + 0.017*\"find\" + 0.015*\"flame\" + 0.014*\"walk\" + 0.014*\"leave\"')\n",
      "(52, '0.337*\"brother\" + 0.063*\"image\" + 0.055*\"evil\" + 0.048*\"tube\" + 0.045*\"float\" + 0.036*\"boot\" + 0.035*\"cookie\" + 0.034*\"former\" + 0.027*\"wine\" + 0.011*\"year\"')\n",
      "(53, '0.152*\"floor\" + 0.105*\"elevator\" + 0.079*\"ticket\" + 0.078*\"level\" + 0.044*\"bear\" + 0.031*\"platform\" + 0.030*\"rise\" + 0.027*\"fall\" + 0.015*\"tiger\" + 0.015*\"horrible\"')\n",
      "(54, '0.139*\"building\" + 0.037*\"build\" + 0.024*\"room\" + 0.023*\"screen\" + 0.022*\"walk\" + 0.021*\"find\" + 0.019*\"leave\" + 0.019*\"towel\" + 0.019*\"place\" + 0.018*\"work\"')\n",
      "(55, '0.206*\"woman\" + 0.034*\"young\" + 0.024*\"dress\" + 0.017*\"wear\" + 0.016*\"walk\" + 0.015*\"hair\" + 0.014*\"black\" + 0.013*\"husband\" + 0.012*\"beautiful\" + 0.012*\"large\"')\n",
      "(56, '0.057*\"walk\" + 0.053*\"jump\" + 0.042*\"fall\" + 0.029*\"stair\" + 0.023*\"step\" + 0.022*\"path\" + 0.021*\"climb\" + 0.019*\"away\" + 0.017*\"high\" + 0.016*\"afraid\"')\n",
      "(57, '0.068*\"basement\" + 0.048*\"crowd\" + 0.039*\"football\" + 0.033*\"tent\" + 0.026*\"wind\" + 0.021*\"chest\" + 0.017*\"small\" + 0.017*\"rifle\" + 0.016*\"arrow\" + 0.013*\"hunting\"')\n",
      "(58, '0.274*\"love\" + 0.029*\"site\" + 0.028*\"together\" + 0.021*\"also\" + 0.020*\"meter\" + 0.017*\"dentist\" + 0.016*\"later\" + 0.014*\"giggle\" + 0.013*\"human\" + 0.012*\"artist\"')\n",
      "(59, '0.097*\"sign\" + 0.069*\"complain\" + 0.067*\"check\" + 0.064*\"sheet\" + 0.047*\"sometimes\" + 0.037*\"magazine\" + 0.025*\"form\" + 0.025*\"yesterday\" + 0.023*\"free\" + 0.022*\"work\"')\n",
      "(60, '0.160*\"group\" + 0.100*\"line\" + 0.022*\"leave\" + 0.017*\"wait\" + 0.017*\"walk\" + 0.017*\"stand\" + 0.013*\"right\" + 0.013*\"join\" + 0.013*\"base\" + 0.011*\"move\"')\n",
      "(61, '0.188*\"child\" + 0.033*\"cream\" + 0.027*\"wish\" + 0.023*\"woke\" + 0.018*\"feel\" + 0.013*\"release\" + 0.013*\"corn\" + 0.012*\"much\" + 0.011*\"live\" + 0.010*\"terrible\"')\n",
      "(62, '0.210*\"picture\" + 0.078*\"snow\" + 0.069*\"paint\" + 0.054*\"present\" + 0.050*\"flower\" + 0.028*\"afterwards\" + 0.023*\"painting\" + 0.022*\"reality\" + 0.021*\"subject\" + 0.018*\"post\"')\n",
      "(63, '0.172*\"dance\" + 0.165*\"kiss\" + 0.051*\"cage\" + 0.028*\"argue\" + 0.028*\"hell\" + 0.027*\"winner\" + 0.025*\"club\" + 0.023*\"real_life\" + 0.023*\"mouse\" + 0.021*\"annoying\"')\n",
      "(64, '0.111*\"class\" + 0.088*\"teacher\" + 0.069*\"student\" + 0.035*\"room\" + 0.031*\"classroom\" + 0.030*\"university\" + 0.028*\"grade\" + 0.024*\"teach\" + 0.019*\"college\" + 0.014*\"first\"')\n",
      "(65, '0.102*\"wife\" + 0.021*\"engine\" + 0.018*\"stop\" + 0.017*\"speed\" + 0.015*\"hand\" + 0.014*\"brake\" + 0.014*\"yell\" + 0.013*\"unknown\" + 0.013*\"pull\" + 0.013*\"battery\"')\n",
      "(66, '0.150*\"watch\" + 0.139*\"movie\" + 0.034*\"show\" + 0.032*\"different\" + 0.025*\"mention\" + 0.023*\"later\" + 0.023*\"girl\" + 0.021*\"next\" + 0.016*\"also\" + 0.016*\"desk\"')\n",
      "(67, '0.130*\"test\" + 0.129*\"computer\" + 0.061*\"chocolate\" + 0.043*\"give\" + 0.031*\"boss\" + 0.024*\"work\" + 0.023*\"result\" + 0.021*\"score\" + 0.020*\"fail\" + 0.019*\"television\"')\n",
      "(68, '0.194*\"door\" + 0.068*\"open\" + 0.058*\"room\" + 0.035*\"lock\" + 0.034*\"leave\" + 0.031*\"close\" + 0.029*\"window\" + 0.024*\"ezra\" + 0.020*\"front\" + 0.019*\"keep\"')\n",
      "(69, '0.095*\"hospital\" + 0.080*\"hour\" + 0.065*\"bird\" + 0.054*\"patient\" + 0.044*\"clock\" + 0.031*\"nurse\" + 0.027*\"breakfast\" + 0.027*\"pizza\" + 0.021*\"screw\" + 0.019*\"ramp\"')\n",
      "(70, '0.063*\"work\" + 0.052*\"file\" + 0.049*\"punch\" + 0.045*\"information\" + 0.026*\"figure\" + 0.019*\"companion\" + 0.018*\"examine\" + 0.017*\"presentation\" + 0.016*\"need\" + 0.015*\"broke\"')\n",
      "(71, '0.499*\"girl\" + 0.041*\"date\" + 0.028*\"little\" + 0.022*\"year\" + 0.018*\"young\" + 0.017*\"downtown\" + 0.011*\"rich\" + 0.011*\"show\" + 0.010*\"pretty\" + 0.009*\"frog\"')\n",
      "(72, '0.035*\"cabin\" + 0.030*\"large\" + 0.027*\"dirt\" + 0.023*\"small\" + 0.018*\"wooden\" + 0.016*\"patio\" + 0.016*\"relative\" + 0.015*\"object\" + 0.012*\"paddle\" + 0.012*\"dock\"')\n",
      "(73, '0.138*\"fish\" + 0.068*\"library\" + 0.064*\"hair\" + 0.060*\"fishing\" + 0.056*\"message\" + 0.048*\"catch\" + 0.045*\"monster\" + 0.041*\"match\" + 0.022*\"line\" + 0.022*\"village\"')\n",
      "(74, '0.188*\"mother\" + 0.123*\"home\" + 0.083*\"sister\" + 0.043*\"live\" + 0.041*\"house\" + 0.017*\"visit\" + 0.016*\"family\" + 0.013*\"rain\" + 0.012*\"time\" + 0.011*\"driveway\"')\n",
      "(75, '0.039*\"feel\" + 0.023*\"help\" + 0.021*\"leave\" + 0.021*\"father\" + 0.020*\"family\" + 0.013*\"move\" + 0.012*\"hand\" + 0.011*\"much\" + 0.010*\"life\" + 0.010*\"time\"')\n",
      "(76, '0.137*\"book\" + 0.117*\"write\" + 0.086*\"read\" + 0.084*\"paper\" + 0.032*\"page\" + 0.023*\"letter\" + 0.020*\"list\" + 0.019*\"newspaper\" + 0.017*\"story\" + 0.017*\"writing\"')\n",
      "(77, '0.093*\"room\" + 0.027*\"floor\" + 0.024*\"apartment\" + 0.019*\"wall\" + 0.018*\"move\" + 0.018*\"large\" + 0.016*\"walk\" + 0.015*\"small\" + 0.015*\"door\" + 0.014*\"window\"')\n",
      "(78, '0.071*\"shoot\" + 0.024*\"escape\" + 0.023*\"soldier\" + 0.021*\"fire\" + 0.018*\"pain\" + 0.017*\"hand\" + 0.016*\"explode\" + 0.014*\"head\" + 0.014*\"away\" + 0.013*\"enemy\"')\n",
      "(79, '0.068*\"stage\" + 0.058*\"play\" + 0.056*\"song\" + 0.056*\"singe\" + 0.054*\"sing\" + 0.050*\"voice\" + 0.045*\"record\" + 0.038*\"show\" + 0.028*\"audience\" + 0.028*\"part\"')\n",
      "(80, '0.151*\"tape\" + 0.081*\"board\" + 0.059*\"sick\" + 0.027*\"stupid\" + 0.024*\"campus\" + 0.019*\"cross\" + 0.017*\"prove\" + 0.015*\"cold\" + 0.014*\"bone\" + 0.013*\"record\"')\n",
      "(81, '0.031*\"time\" + 0.018*\"event\" + 0.017*\"involve\" + 0.016*\"work\" + 0.013*\"also\" + 0.013*\"first\" + 0.012*\"feel\" + 0.011*\"well\" + 0.011*\"year\" + 0.011*\"strike\"')\n",
      "(82, '0.244*\"baby\" + 0.060*\"snake\" + 0.057*\"bike\" + 0.033*\"pregnant\" + 0.027*\"give\" + 0.021*\"ditch\" + 0.020*\"hold\" + 0.016*\"hate\" + 0.015*\"grandmother\" + 0.014*\"feed\"')\n",
      "(83, '0.021*\"fact\" + 0.019*\"program\" + 0.017*\"little\" + 0.016*\"interpretation\" + 0.015*\"time\" + 0.015*\"believe\" + 0.015*\"stranger\" + 0.014*\"feel\" + 0.014*\"perhaps\" + 0.013*\"probably\"')\n",
      "(84, '0.116*\"feel\" + 0.022*\"hand\" + 0.017*\"feeling\" + 0.012*\"leave\" + 0.012*\"hurt\" + 0.011*\"penis\" + 0.011*\"sexual\" + 0.011*\"lean\" + 0.010*\"walk\" + 0.009*\"pull\"')\n",
      "(85, '0.100*\"office\" + 0.038*\"work\" + 0.037*\"feel\" + 0.027*\"time\" + 0.019*\"relationship\" + 0.018*\"desk\" + 0.017*\"good\" + 0.015*\"agree\" + 0.010*\"company\" + 0.009*\"room\"')\n",
      "(86, '0.076*\"bottle\" + 0.064*\"yellow\" + 0.044*\"plastic\" + 0.036*\"pink\" + 0.033*\"doll\" + 0.030*\"star\" + 0.028*\"pour\" + 0.022*\"pick\" + 0.022*\"blue\" + 0.021*\"hair\"')\n",
      "(87, '0.084*\"chicken\" + 0.058*\"plant\" + 0.055*\"wire\" + 0.037*\"grow\" + 0.033*\"professor\" + 0.031*\"forest\" + 0.027*\"unit\" + 0.021*\"entrance\" + 0.019*\"also\" + 0.017*\"speaker\"')\n",
      "(88, '0.181*\"truck\" + 0.021*\"third\" + 0.018*\"tire\" + 0.017*\"account\" + 0.016*\"time\" + 0.015*\"lately\" + 0.012*\"went\" + 0.012*\"coat\" + 0.012*\"equipment\" + 0.010*\"alcohol\"')\n",
      "(89, '0.409*\"friend\" + 0.032*\"daughter\" + 0.029*\"really\" + 0.026*\"cousin\" + 0.015*\"good\" + 0.012*\"year\" + 0.012*\"camp\" + 0.011*\"also\" + 0.011*\"apartment\" + 0.010*\"character\"')\n",
      "(90, '0.125*\"party\" + 0.108*\"field\" + 0.075*\"team\" + 0.051*\"player\" + 0.037*\"baseball\" + 0.033*\"game\" + 0.027*\"play\" + 0.026*\"bomb\" + 0.022*\"first\" + 0.017*\"audio\"')\n",
      "(91, '0.054*\"town\" + 0.035*\"mountain\" + 0.031*\"wood\" + 0.025*\"direction\" + 0.016*\"bicycle\" + 0.014*\"brick\" + 0.012*\"hand\" + 0.012*\"branch\" + 0.011*\"purse\" + 0.011*\"small\"')\n",
      "(92, '0.156*\"bathroom\" + 0.072*\"shower\" + 0.039*\"toilet\" + 0.031*\"room\" + 0.022*\"find\" + 0.022*\"curtain\" + 0.020*\"dinosaur\" + 0.017*\"worker\" + 0.015*\"need\" + 0.015*\"keep\"')\n",
      "(93, '0.044*\"ghost\" + 0.041*\"candy\" + 0.035*\"package\" + 0.031*\"really\" + 0.028*\"meat\" + 0.027*\"skate\" + 0.027*\"giant\" + 0.024*\"motor\" + 0.020*\"poke\" + 0.018*\"huge\"')\n",
      "(94, '0.092*\"blood\" + 0.055*\"suit\" + 0.027*\"flash\" + 0.027*\"cover\" + 0.027*\"lion\" + 0.025*\"noise\" + 0.023*\"repair\" + 0.017*\"email\" + 0.016*\"bleed\" + 0.015*\"nate\"')\n",
      "(95, '0.113*\"glass\" + 0.083*\"pack\" + 0.030*\"cigarette\" + 0.030*\"farm\" + 0.028*\"container\" + 0.026*\"airplane\" + 0.022*\"give\" + 0.020*\"liquid\" + 0.018*\"spell\" + 0.017*\"oval\"')\n",
      "(96, '0.106*\"parent\" + 0.084*\"girlfriend\" + 0.039*\"station\" + 0.028*\"duck\" + 0.026*\"court\" + 0.019*\"feel\" + 0.014*\"confusion\" + 0.014*\"good\" + 0.013*\"many\" + 0.013*\"situation\"')\n",
      "(97, '0.096*\"hotel\" + 0.074*\"room\" + 0.056*\"video\" + 0.032*\"bench\" + 0.030*\"episode\" + 0.027*\"watch\" + 0.025*\"later\" + 0.024*\"beer\" + 0.019*\"somewhere\" + 0.018*\"place\"')\n",
      "(98, '0.108*\"police\" + 0.043*\"creature\" + 0.039*\"burn\" + 0.029*\"kitten\" + 0.027*\"alive\" + 0.022*\"grandma\" + 0.022*\"black\" + 0.019*\"weapon\" + 0.016*\"freak\" + 0.016*\"secret\"')\n",
      "(99, '0.055*\"problem\" + 0.042*\"work\" + 0.035*\"time\" + 0.022*\"bowl\" + 0.016*\"scene\" + 0.014*\"shell\" + 0.012*\"really\" + 0.011*\"kind\" + 0.011*\"part\" + 0.011*\"color\"')\n"
     ]
    }
   ],
   "source": [
    "topics = lda_model.print_topics(100)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
    "\n",
    "    # Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.to_csv(f\"{data_directory}/topic_example_100_analysis.csv\", sep=\";\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.2747</td>\n",
       "      <td>room, floor, apartment, wall, move, large, wal...</td>\n",
       "      <td>[european, piper, sort, house, side, second, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>drive, stop, road, leave, turn, driver, park, ...</td>\n",
       "      <td>[large, fine, house, ground, maybe, rent, publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.1084</td>\n",
       "      <td>time, event, involve, work, also, first, feel,...</td>\n",
       "      <td>[watch, plane, shortly, realize, crash, half, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>sort, little, rather, place, quite, right, muc...</td>\n",
       "      <td>[pull, green, leave, berry, branch, live, grow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>sort, little, rather, place, quite, right, muc...</td>\n",
       "      <td>[room, remind, definitely, street, live, least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>room, floor, apartment, wall, move, large, wal...</td>\n",
       "      <td>[live, next, door, apartment, move, move, plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>time, leave, realize, decide, maybe, bill, als...</td>\n",
       "      <td>[kidnap, stop, visit, house, building, togethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.2524</td>\n",
       "      <td>knife, text, stab, asian, blind, count, word, ...</td>\n",
       "      <td>[alone, apartment, place, build, dark, maybe, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.2799</td>\n",
       "      <td>sort, little, rather, place, quite, right, muc...</td>\n",
       "      <td>[somewhere, friend, around, much, house, elsew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.2898</td>\n",
       "      <td>time, event, involve, work, also, first, feel,...</td>\n",
       "      <td>[public, place, remind, grocery_store, airport...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0            77.0              0.2747   \n",
       "1            1             8.0              0.2133   \n",
       "2            2            81.0              0.1084   \n",
       "3            3            50.0              0.2574   \n",
       "4            4            50.0              0.2701   \n",
       "5            5            77.0              0.2425   \n",
       "6            6            45.0              0.2243   \n",
       "7            7            20.0              0.2524   \n",
       "8            8            50.0              0.2799   \n",
       "9            9            81.0              0.2898   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  room, floor, apartment, wall, move, large, wal...   \n",
       "1  drive, stop, road, leave, turn, driver, park, ...   \n",
       "2  time, event, involve, work, also, first, feel,...   \n",
       "3  sort, little, rather, place, quite, right, muc...   \n",
       "4  sort, little, rather, place, quite, right, muc...   \n",
       "5  room, floor, apartment, wall, move, large, wal...   \n",
       "6  time, leave, realize, decide, maybe, bill, als...   \n",
       "7  knife, text, stab, asian, blind, count, word, ...   \n",
       "8  sort, little, rather, place, quite, right, muc...   \n",
       "9  time, event, involve, work, also, first, feel,...   \n",
       "\n",
       "                                                Text  \n",
       "0  [european, piper, sort, house, side, second, i...  \n",
       "1  [large, fine, house, ground, maybe, rent, publ...  \n",
       "2  [watch, plane, shortly, realize, crash, half, ...  \n",
       "3  [pull, green, leave, berry, branch, live, grow...  \n",
       "4  [room, remind, definitely, street, live, least...  \n",
       "5  [live, next, door, apartment, move, move, plac...  \n",
       "6  [kidnap, stop, visit, house, building, togethe...  \n",
       "7  [alone, apartment, place, build, dark, maybe, ...  \n",
       "8  [somewhere, friend, around, much, house, elsew...  \n",
       "9  [public, place, remind, grocery_store, airport...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77.,  8., 81., 50., 45., 20., 35., 91., 89., 11., 56., 75., 70.,\n",
       "       54., 19., 25., 37.,  2., 32., 68., 60., 39., 84., 46., 12., 28.,\n",
       "       55., 96., 85., 15., 66., 95., 22., 48., 78., 23., 43., 88., 64.,\n",
       "       99., 98., 47., 17., 40., 51., 61., 74., 16., 94., 33., 82., 63.,\n",
       "       26.,  0., 30.,  3., 24., 71., 34.,  7., 44., 92., 79., 58., 76.,\n",
       "       72., 41., 90.,  9., 80., 52., 69., 10., 36., 13., 86., 97., 18.,\n",
       "        6., 73., 53., 87., 83., 67., 27., 31., 57., 38., 93., 65., 59.,\n",
       "       21., 49.,  5., 62.,  1.,  4., 42., 29., 14., nan])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic['Dominant_Topic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sue√±os asignados a topicos:  36009\n",
      "      Dominant_Topic\n",
      "35.0            1845\n",
      "77.0            1697\n",
      "45.0            1363\n",
      "68.0            1212\n",
      "8.0             1170\n",
      "66.0            1095\n",
      "55.0            1041\n",
      "32.0             960\n",
      "56.0             839\n",
      "84.0             829\n",
      "50.0             824\n",
      "39.0             808\n",
      "46.0             750\n",
      "2.0              704\n",
      "15.0             693\n",
      "75.0             681\n",
      "25.0             640\n",
      "24.0             582\n",
      "51.0             539\n",
      "64.0             537\n",
      "21.0             533\n",
      "54.0             510\n",
      "76.0             492\n",
      "74.0             489\n",
      "97.0             481\n",
      "17.0             472\n",
      "85.0             464\n",
      "78.0             460\n",
      "89.0             427\n",
      "41.0             416\n",
      "81.0             404\n",
      "11.0             382\n",
      "60.0             343\n",
      "0.0              310\n",
      "43.0             309\n",
      "83.0             306\n",
      "82.0             299\n",
      "18.0             292\n",
      "28.0             284\n",
      "19.0             283\n",
      "16.0             278\n",
      "71.0             274\n",
      "91.0             268\n",
      "40.0             266\n",
      "99.0             255\n",
      "79.0             245\n",
      "26.0             239\n",
      "33.0             233\n",
      "13.0             227\n",
      "98.0             223\n",
      "7.0              218\n",
      "92.0             203\n",
      "90.0             198\n",
      "65.0             195\n",
      "44.0             190\n",
      "22.0             188\n",
      "67.0             183\n",
      "61.0             183\n",
      "3.0              179\n",
      "12.0             175\n",
      "58.0             169\n",
      "87.0             164\n",
      "69.0             161\n",
      "72.0             159\n",
      "10.0             157\n",
      "53.0             154\n",
      "47.0             151\n",
      "59.0             149\n",
      "27.0             149\n",
      "86.0             146\n",
      "93.0             145\n",
      "96.0             140\n",
      "29.0             135\n",
      "49.0             135\n",
      "73.0             134\n",
      "34.0             133\n",
      "48.0             132\n",
      "23.0             132\n",
      "63.0             130\n",
      "38.0             130\n",
      "30.0             127\n",
      "14.0             126\n",
      "70.0             119\n",
      "9.0              117\n",
      "37.0             116\n",
      "88.0             113\n",
      "57.0             109\n",
      "95.0             107\n",
      "62.0             104\n",
      "31.0              95\n",
      "6.0               89\n",
      "94.0              89\n",
      "42.0              85\n",
      "36.0              84\n",
      "4.0               82\n",
      "5.0               81\n",
      "20.0              74\n",
      "1.0               72\n",
      "80.0              71\n",
      "52.0              59\n"
     ]
    }
   ],
   "source": [
    "tmp=df_dominant_topic['Dominant_Topic'].value_counts()\n",
    "df=pd.DataFrame(tmp)\n",
    "pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "print(\"#sue√±os asignados a topicos: \",df['Dominant_Topic'].sum())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
